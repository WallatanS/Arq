{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importar bibliotecas e carregar os dados:"
      ],
      "metadata": {
        "id": "lslwxtJSAo1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discentes: \n",
        "\n",
        "*   **Vinicius de Moraes**\n",
        "*   **Wallatan França**\n",
        "\n"
      ],
      "metadata": {
        "id": "BkzKye6gTs4q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XOF_qIY9UXDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Breast Cancer Wisconsin (Diagnostic) Dataset:\n",
        "\n",
        "Descrição: Conjunto de dados com informações sobre características de células de tecido mamário.\n",
        "Tarefa: Classificação de diagnóstico de câncer de mama (maligno ou benigno)."
      ],
      "metadata": {
        "id": "TyQCSWAZBINp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "pXCB-erztAlk"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas necessárias para a construção do modelo e pré-processamento dos dados\n",
        "import tensorflow as tf  # TensorFlow para construção do modelo de rede neural\n",
        "from tensorflow import keras  # Keras para simplificar a construção do modelo\n",
        "import numpy as np  # NumPy para operações numéricas\n",
        "from sklearn.model_selection import train_test_split  # Scikit-learn para divisão dos dados em conjuntos de treinamento e teste\n",
        "from sklearn.preprocessing import StandardScaler  # Scikit-learn para pré-processamento dos dados\n",
        "from sklearn.datasets import load_breast_cancer  # Scikit-learn para carregar o conjunto de dados do câncer de mama\n",
        "import matplotlib.pyplot as plt # Importar a biblioteca matplotlib para visualização de dados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o conjunto de dados do câncer de mama usando a função load_breast_cancer() do scikit-learn\n",
        "data = load_breast_cancer()\n",
        "# Armazenar as características (dados de entrada) na variável X e os rótulos na variável y\n",
        "X, y = data.data, data.target\n",
        "\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste usando a função train_test_split() do scikit-learn\n",
        "# O tamanho do conjunto de teste é definido como 20% dos dados totais\n",
        "# O parâmetro random_state garante que a divisão seja reproduzível\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
        "\n",
        "# Pré-processar os dados normalizando-os usando a classe StandardScaler do scikit-learn\n",
        "# Criamos uma instância do StandardScaler\n",
        "scaler = StandardScaler()\n",
        "# Aplicamos a normalização aos dados de treinamento usando fit_transform()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "# Aplicamos a mesma transformação aos dados de teste usando transform()\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "ANE-m155tmNe"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
        "column_names = [\"ID\", \"Diagnosis\", \"Mean Radius\", \"Mean Texture\", \"Mean Perimeter\", \"Mean Area\", \"Mean Smoothness\", \"Mean Compactness\",\n",
        "                \"Mean Concavity\", \"Mean Concave Points\", \"Mean Symmetry\", \"Mean Fractal Dimension\", \"SE Radius\", \"SE Texture\",\n",
        "                \"SE Perimeter\", \"SE Area\", \"SE Smoothness\", \"SE Compactness\", \"SE Concavity\", \"SE Concave Points\", \"SE Symmetry\",\n",
        "                \"SE Fractal Dimension\", \"Worst Radius\", \"Worst Texture\", \"Worst Perimeter\", \"Worst Area\", \"Worst Smoothness\",\n",
        "                \"Worst Compactness\", \"Worst Concavity\", \"Worst Concave Points\", \"Worst Symmetry\", \"Worst Fractal Dimension\"]\n",
        "\n",
        "dataset = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Exibir a tabela\n",
        "dataset.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "d4D1w1-qFFj5",
        "outputId": "48e8873f-fc28-42fc-e7f1-e44f75820cb0"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID Diagnosis  Mean Radius  Mean Texture  Mean Perimeter  Mean Area  \\\n",
              "0     842302         M       17.990         10.38          122.80     1001.0   \n",
              "1     842517         M       20.570         17.77          132.90     1326.0   \n",
              "2   84300903         M       19.690         21.25          130.00     1203.0   \n",
              "3   84348301         M       11.420         20.38           77.58      386.1   \n",
              "4   84358402         M       20.290         14.34          135.10     1297.0   \n",
              "..       ...       ...          ...           ...             ...        ...   \n",
              "95     86208         M       20.260         23.03          132.40     1264.0   \n",
              "96     86211         B       12.180         17.84           77.79      451.1   \n",
              "97    862261         B        9.787         19.94           62.11      294.5   \n",
              "98    862485         B       11.600         12.84           74.34      412.6   \n",
              "99    862548         M       14.420         19.77           94.48      642.5   \n",
              "\n",
              "    Mean Smoothness  Mean Compactness  Mean Concavity  Mean Concave Points  \\\n",
              "0           0.11840           0.27760        0.300100             0.147100   \n",
              "1           0.08474           0.07864        0.086900             0.070170   \n",
              "2           0.10960           0.15990        0.197400             0.127900   \n",
              "3           0.14250           0.28390        0.241400             0.105200   \n",
              "4           0.10030           0.13280        0.198000             0.104300   \n",
              "..              ...               ...             ...                  ...   \n",
              "95          0.09078           0.13130        0.146500             0.086830   \n",
              "96          0.10450           0.07057        0.024900             0.029410   \n",
              "97          0.10240           0.05301        0.006829             0.007937   \n",
              "98          0.08983           0.07525        0.041960             0.033500   \n",
              "99          0.09752           0.11410        0.093880             0.058390   \n",
              "\n",
              "    ...  Worst Radius  Worst Texture  Worst Perimeter  Worst Area  \\\n",
              "0   ...         25.38          17.33           184.60      2019.0   \n",
              "1   ...         24.99          23.41           158.80      1956.0   \n",
              "2   ...         23.57          25.53           152.50      1709.0   \n",
              "3   ...         14.91          26.50            98.87       567.7   \n",
              "4   ...         22.54          16.67           152.20      1575.0   \n",
              "..  ...           ...            ...              ...         ...   \n",
              "95  ...         24.22          31.59           156.10      1750.0   \n",
              "96  ...         12.83          20.92            82.14       495.2   \n",
              "97  ...         10.92          26.29            68.81       366.1   \n",
              "98  ...         13.06          17.16            82.96       512.5   \n",
              "99  ...         16.33          30.86           109.50       826.4   \n",
              "\n",
              "    Worst Smoothness  Worst Compactness  Worst Concavity  \\\n",
              "0             0.1622            0.66560          0.71190   \n",
              "1             0.1238            0.18660          0.24160   \n",
              "2             0.1444            0.42450          0.45040   \n",
              "3             0.2098            0.86630          0.68690   \n",
              "4             0.1374            0.20500          0.40000   \n",
              "..               ...                ...              ...   \n",
              "95            0.1190            0.35390          0.40980   \n",
              "96            0.1140            0.09358          0.04980   \n",
              "97            0.1316            0.09473          0.02049   \n",
              "98            0.1431            0.18510          0.19220   \n",
              "99            0.1431            0.30260          0.31940   \n",
              "\n",
              "    Worst Concave Points  Worst Symmetry  Worst Fractal Dimension  \n",
              "0                0.26540          0.4601                  0.11890  \n",
              "1                0.18600          0.2750                  0.08902  \n",
              "2                0.24300          0.3613                  0.08758  \n",
              "3                0.25750          0.6638                  0.17300  \n",
              "4                0.16250          0.2364                  0.07678  \n",
              "..                   ...             ...                      ...  \n",
              "95               0.15730          0.3689                  0.08368  \n",
              "96               0.05882          0.2227                  0.07376  \n",
              "97               0.02381          0.1934                  0.08988  \n",
              "98               0.08449          0.2772                  0.08756  \n",
              "99               0.15650          0.2718                  0.09353  \n",
              "\n",
              "[100 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-145a05d6-9386-4c5b-8082-5326d1bb3ec5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Mean Radius</th>\n",
              "      <th>Mean Texture</th>\n",
              "      <th>Mean Perimeter</th>\n",
              "      <th>Mean Area</th>\n",
              "      <th>Mean Smoothness</th>\n",
              "      <th>Mean Compactness</th>\n",
              "      <th>Mean Concavity</th>\n",
              "      <th>Mean Concave Points</th>\n",
              "      <th>...</th>\n",
              "      <th>Worst Radius</th>\n",
              "      <th>Worst Texture</th>\n",
              "      <th>Worst Perimeter</th>\n",
              "      <th>Worst Area</th>\n",
              "      <th>Worst Smoothness</th>\n",
              "      <th>Worst Compactness</th>\n",
              "      <th>Worst Concavity</th>\n",
              "      <th>Worst Concave Points</th>\n",
              "      <th>Worst Symmetry</th>\n",
              "      <th>Worst Fractal Dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.990</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.300100</td>\n",
              "      <td>0.147100</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.71190</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.570</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.086900</td>\n",
              "      <td>0.070170</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.24160</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.197400</td>\n",
              "      <td>0.127900</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.420</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.241400</td>\n",
              "      <td>0.105200</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.68690</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.290</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.198000</td>\n",
              "      <td>0.104300</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.40000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>86208</td>\n",
              "      <td>M</td>\n",
              "      <td>20.260</td>\n",
              "      <td>23.03</td>\n",
              "      <td>132.40</td>\n",
              "      <td>1264.0</td>\n",
              "      <td>0.09078</td>\n",
              "      <td>0.13130</td>\n",
              "      <td>0.146500</td>\n",
              "      <td>0.086830</td>\n",
              "      <td>...</td>\n",
              "      <td>24.22</td>\n",
              "      <td>31.59</td>\n",
              "      <td>156.10</td>\n",
              "      <td>1750.0</td>\n",
              "      <td>0.1190</td>\n",
              "      <td>0.35390</td>\n",
              "      <td>0.40980</td>\n",
              "      <td>0.15730</td>\n",
              "      <td>0.3689</td>\n",
              "      <td>0.08368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>86211</td>\n",
              "      <td>B</td>\n",
              "      <td>12.180</td>\n",
              "      <td>17.84</td>\n",
              "      <td>77.79</td>\n",
              "      <td>451.1</td>\n",
              "      <td>0.10450</td>\n",
              "      <td>0.07057</td>\n",
              "      <td>0.024900</td>\n",
              "      <td>0.029410</td>\n",
              "      <td>...</td>\n",
              "      <td>12.83</td>\n",
              "      <td>20.92</td>\n",
              "      <td>82.14</td>\n",
              "      <td>495.2</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.09358</td>\n",
              "      <td>0.04980</td>\n",
              "      <td>0.05882</td>\n",
              "      <td>0.2227</td>\n",
              "      <td>0.07376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>862261</td>\n",
              "      <td>B</td>\n",
              "      <td>9.787</td>\n",
              "      <td>19.94</td>\n",
              "      <td>62.11</td>\n",
              "      <td>294.5</td>\n",
              "      <td>0.10240</td>\n",
              "      <td>0.05301</td>\n",
              "      <td>0.006829</td>\n",
              "      <td>0.007937</td>\n",
              "      <td>...</td>\n",
              "      <td>10.92</td>\n",
              "      <td>26.29</td>\n",
              "      <td>68.81</td>\n",
              "      <td>366.1</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.09473</td>\n",
              "      <td>0.02049</td>\n",
              "      <td>0.02381</td>\n",
              "      <td>0.1934</td>\n",
              "      <td>0.08988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>862485</td>\n",
              "      <td>B</td>\n",
              "      <td>11.600</td>\n",
              "      <td>12.84</td>\n",
              "      <td>74.34</td>\n",
              "      <td>412.6</td>\n",
              "      <td>0.08983</td>\n",
              "      <td>0.07525</td>\n",
              "      <td>0.041960</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>...</td>\n",
              "      <td>13.06</td>\n",
              "      <td>17.16</td>\n",
              "      <td>82.96</td>\n",
              "      <td>512.5</td>\n",
              "      <td>0.1431</td>\n",
              "      <td>0.18510</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.08449</td>\n",
              "      <td>0.2772</td>\n",
              "      <td>0.08756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>862548</td>\n",
              "      <td>M</td>\n",
              "      <td>14.420</td>\n",
              "      <td>19.77</td>\n",
              "      <td>94.48</td>\n",
              "      <td>642.5</td>\n",
              "      <td>0.09752</td>\n",
              "      <td>0.11410</td>\n",
              "      <td>0.093880</td>\n",
              "      <td>0.058390</td>\n",
              "      <td>...</td>\n",
              "      <td>16.33</td>\n",
              "      <td>30.86</td>\n",
              "      <td>109.50</td>\n",
              "      <td>826.4</td>\n",
              "      <td>0.1431</td>\n",
              "      <td>0.30260</td>\n",
              "      <td>0.31940</td>\n",
              "      <td>0.15650</td>\n",
              "      <td>0.2718</td>\n",
              "      <td>0.09353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-145a05d6-9386-4c5b-8082-5326d1bb3ec5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-145a05d6-9386-4c5b-8082-5326d1bb3ec5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-145a05d6-9386-4c5b-8082-5326d1bb3ec5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir a arquitetura da rede neural"
      ],
      "metadata": {
        "id": "ktHG3gbxAxkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A linha de código `keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],))` cria uma camada densa (fully connected layer) em uma rede neural usando a biblioteca Keras.\n",
        "\n",
        "- `keras.layers.Dense`: Indica que estamos adicionando uma camada densa à nossa rede neural.\n",
        "\n",
        "- `64`: Especifica o número de neurônios (unidades) nesta camada. Neste caso, a camada terá 64 neurônios.\n",
        "\n",
        "- `activation='relu'`: Define a função de ativação a ser aplicada a cada neurônio na camada. Neste caso, usamos a função ReLU (Rectified Linear Unit), que é uma função de ativação não linear comumente usada em redes neurais.\n",
        "\n",
        "- `input_shape=(X_train.shape[1],)`: Especifica a forma de entrada dos dados para esta camada. `X_train.shape[1]` retorna o número de características (ou colunas) dos dados de treinamento `X_train`. Portanto, `input_shape=(X_train.shape[1],)` indica que a camada recebe um vetor de entrada com o mesmo número de características que os dados de treinamento.\n",
        "\n",
        "Essa linha de código cria uma camada densa com 64 neurônios, cada um aplicando a função de ativação ReLU aos dados de entrada. Essa camada é geralmente usada como uma camada intermediária em uma rede neural para aprender características complexas dos dados."
      ],
      "metadata": {
        "id": "ouVz16VIGP-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o modelo sequencial do Keras\n",
        "model = keras.Sequential([\n",
        "    # Primeira camada densa (fully connected) com 64 neurônios e ativação ReLU\n",
        "    keras.layers.Dense(1, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    # Segunda camada densa (fully connected) com 64 neurônios e ativação ReLU\n",
        "    keras.layers.Dense(1, activation='relu'),\n",
        "    # Camada de saída com 1 neurônio e ativação sigmoidal\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "knoK0RVVtoWi"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilar e treinar o modelo:"
      ],
      "metadata": {
        "id": "7rnBFpR-A1th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar o modelo com a função de perda, otimizador e métricas\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Compilação do modelo usando a função compile() do Keras\n",
        "# Definimos a função de perda como 'binary_crossentropy' para problemas de classificação binária\n",
        "# Escolhemos o otimizador 'adam' para ajustar os pesos do modelo durante o treinamento\n",
        "# As métricas serão calculadas durante o treinamento e avaliação, e no caso especificamos 'accuracy' para a acurácia\n",
        "# Treinar o modelo com os dados de treinamento\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=100, validation_data=(X_test, y_test))\n",
        "# Treinamento do modelo usando a função fit() do Keras\n",
        "# Passamos os dados de treinamento X_train e os rótulos y_train\n",
        "# Definimos o número de épocas como 10, o tamanho do lote como 32\n",
        "# Usamos os dados de teste (X_test, y_test) como conjunto de validação para avaliar o desempenho durante o treinamento"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLmKkr4Htq_u",
        "outputId": "ad03bdbe-b062-4ed6-9fa4-18064f15d9a2"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 57ms/step - loss: 0.6377 - accuracy: 0.6703 - val_loss: 0.6313 - val_accuracy: 0.7895\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6303 - accuracy: 0.7758 - val_loss: 0.6246 - val_accuracy: 0.8070\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.6232 - accuracy: 0.7978 - val_loss: 0.6181 - val_accuracy: 0.8158\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6163 - accuracy: 0.8176 - val_loss: 0.6118 - val_accuracy: 0.8246\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.6100 - accuracy: 0.8330 - val_loss: 0.6056 - val_accuracy: 0.8421\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6037 - accuracy: 0.8352 - val_loss: 0.5997 - val_accuracy: 0.8596\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5978 - accuracy: 0.8396 - val_loss: 0.5940 - val_accuracy: 0.8684\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5920 - accuracy: 0.8462 - val_loss: 0.5886 - val_accuracy: 0.8772\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5863 - accuracy: 0.8505 - val_loss: 0.5834 - val_accuracy: 0.8772\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5812 - accuracy: 0.8505 - val_loss: 0.5782 - val_accuracy: 0.8772\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5760 - accuracy: 0.8571 - val_loss: 0.5732 - val_accuracy: 0.8772\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5708 - accuracy: 0.8593 - val_loss: 0.5683 - val_accuracy: 0.8860\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5658 - accuracy: 0.8637 - val_loss: 0.5636 - val_accuracy: 0.8860\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5608 - accuracy: 0.8747 - val_loss: 0.5590 - val_accuracy: 0.8860\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5561 - accuracy: 0.8791 - val_loss: 0.5546 - val_accuracy: 0.8860\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5514 - accuracy: 0.8901 - val_loss: 0.5503 - val_accuracy: 0.8860\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5468 - accuracy: 0.8901 - val_loss: 0.5462 - val_accuracy: 0.8860\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5423 - accuracy: 0.8923 - val_loss: 0.5421 - val_accuracy: 0.8860\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5380 - accuracy: 0.8945 - val_loss: 0.5381 - val_accuracy: 0.8860\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5338 - accuracy: 0.8989 - val_loss: 0.5342 - val_accuracy: 0.8860\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5296 - accuracy: 0.9011 - val_loss: 0.5305 - val_accuracy: 0.8860\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5256 - accuracy: 0.9033 - val_loss: 0.5269 - val_accuracy: 0.8860\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5218 - accuracy: 0.9055 - val_loss: 0.5233 - val_accuracy: 0.8947\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5179 - accuracy: 0.9077 - val_loss: 0.5199 - val_accuracy: 0.8947\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5142 - accuracy: 0.9077 - val_loss: 0.5165 - val_accuracy: 0.8947\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5105 - accuracy: 0.9077 - val_loss: 0.5131 - val_accuracy: 0.8947\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5070 - accuracy: 0.9099 - val_loss: 0.5100 - val_accuracy: 0.8947\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5036 - accuracy: 0.9121 - val_loss: 0.5068 - val_accuracy: 0.8947\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.5003 - accuracy: 0.9121 - val_loss: 0.5038 - val_accuracy: 0.8947\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4971 - accuracy: 0.9121 - val_loss: 0.5008 - val_accuracy: 0.8947\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4939 - accuracy: 0.9121 - val_loss: 0.4979 - val_accuracy: 0.8947\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4908 - accuracy: 0.9121 - val_loss: 0.4950 - val_accuracy: 0.8947\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4879 - accuracy: 0.9121 - val_loss: 0.4921 - val_accuracy: 0.8947\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4848 - accuracy: 0.9121 - val_loss: 0.4894 - val_accuracy: 0.9035\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4819 - accuracy: 0.9121 - val_loss: 0.4867 - val_accuracy: 0.9035\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4790 - accuracy: 0.9121 - val_loss: 0.4841 - val_accuracy: 0.9035\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4761 - accuracy: 0.9121 - val_loss: 0.4815 - val_accuracy: 0.9035\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4733 - accuracy: 0.9143 - val_loss: 0.4789 - val_accuracy: 0.9035\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4705 - accuracy: 0.9143 - val_loss: 0.4762 - val_accuracy: 0.9035\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.4678 - accuracy: 0.9143 - val_loss: 0.4736 - val_accuracy: 0.9035\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4650 - accuracy: 0.9165 - val_loss: 0.4709 - val_accuracy: 0.9035\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4622 - accuracy: 0.9165 - val_loss: 0.4683 - val_accuracy: 0.9035\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4596 - accuracy: 0.9165 - val_loss: 0.4657 - val_accuracy: 0.9035\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4569 - accuracy: 0.9165 - val_loss: 0.4631 - val_accuracy: 0.9123\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4543 - accuracy: 0.9187 - val_loss: 0.4605 - val_accuracy: 0.9123\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4517 - accuracy: 0.9209 - val_loss: 0.4580 - val_accuracy: 0.9123\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4491 - accuracy: 0.9209 - val_loss: 0.4555 - val_accuracy: 0.9123\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4465 - accuracy: 0.9209 - val_loss: 0.4530 - val_accuracy: 0.9123\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4440 - accuracy: 0.9187 - val_loss: 0.4504 - val_accuracy: 0.9123\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4415 - accuracy: 0.9231 - val_loss: 0.4480 - val_accuracy: 0.9211\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4390 - accuracy: 0.9231 - val_loss: 0.4455 - val_accuracy: 0.9211\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4365 - accuracy: 0.9253 - val_loss: 0.4431 - val_accuracy: 0.9211\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4341 - accuracy: 0.9275 - val_loss: 0.4408 - val_accuracy: 0.9211\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4318 - accuracy: 0.9275 - val_loss: 0.4386 - val_accuracy: 0.9298\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4294 - accuracy: 0.9297 - val_loss: 0.4363 - val_accuracy: 0.9298\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4271 - accuracy: 0.9297 - val_loss: 0.4341 - val_accuracy: 0.9298\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.9341 - val_loss: 0.4318 - val_accuracy: 0.9298\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4224 - accuracy: 0.9341 - val_loss: 0.4295 - val_accuracy: 0.9386\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4201 - accuracy: 0.9341 - val_loss: 0.4272 - val_accuracy: 0.9386\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4179 - accuracy: 0.9341 - val_loss: 0.4250 - val_accuracy: 0.9386\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4156 - accuracy: 0.9363 - val_loss: 0.4227 - val_accuracy: 0.9386\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.4132 - accuracy: 0.9363 - val_loss: 0.4205 - val_accuracy: 0.9386\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4112 - accuracy: 0.9363 - val_loss: 0.4183 - val_accuracy: 0.9386\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4090 - accuracy: 0.9385 - val_loss: 0.4162 - val_accuracy: 0.9474\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4070 - accuracy: 0.9385 - val_loss: 0.4140 - val_accuracy: 0.9474\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4048 - accuracy: 0.9385 - val_loss: 0.4118 - val_accuracy: 0.9474\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.9407 - val_loss: 0.4097 - val_accuracy: 0.9474\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4008 - accuracy: 0.9429 - val_loss: 0.4076 - val_accuracy: 0.9474\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3988 - accuracy: 0.9429 - val_loss: 0.4056 - val_accuracy: 0.9474\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3969 - accuracy: 0.9429 - val_loss: 0.4035 - val_accuracy: 0.9474\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3949 - accuracy: 0.9429 - val_loss: 0.4016 - val_accuracy: 0.9474\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3930 - accuracy: 0.9451 - val_loss: 0.3995 - val_accuracy: 0.9474\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3910 - accuracy: 0.9473 - val_loss: 0.3976 - val_accuracy: 0.9474\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3892 - accuracy: 0.9473 - val_loss: 0.3956 - val_accuracy: 0.9474\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3873 - accuracy: 0.9473 - val_loss: 0.3937 - val_accuracy: 0.9474\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3855 - accuracy: 0.9473 - val_loss: 0.3919 - val_accuracy: 0.9474\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3837 - accuracy: 0.9473 - val_loss: 0.3901 - val_accuracy: 0.9386\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3819 - accuracy: 0.9495 - val_loss: 0.3883 - val_accuracy: 0.9386\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3801 - accuracy: 0.9495 - val_loss: 0.3866 - val_accuracy: 0.9386\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3784 - accuracy: 0.9516 - val_loss: 0.3849 - val_accuracy: 0.9386\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3767 - accuracy: 0.9516 - val_loss: 0.3833 - val_accuracy: 0.9474\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3751 - accuracy: 0.9516 - val_loss: 0.3816 - val_accuracy: 0.9474\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3734 - accuracy: 0.9516 - val_loss: 0.3800 - val_accuracy: 0.9474\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3718 - accuracy: 0.9516 - val_loss: 0.3784 - val_accuracy: 0.9474\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3701 - accuracy: 0.9538 - val_loss: 0.3769 - val_accuracy: 0.9474\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3685 - accuracy: 0.9560 - val_loss: 0.3754 - val_accuracy: 0.9474\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3669 - accuracy: 0.9560 - val_loss: 0.3738 - val_accuracy: 0.9474\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3653 - accuracy: 0.9560 - val_loss: 0.3724 - val_accuracy: 0.9474\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3637 - accuracy: 0.9560 - val_loss: 0.3709 - val_accuracy: 0.9474\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3622 - accuracy: 0.9560 - val_loss: 0.3694 - val_accuracy: 0.9474\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3607 - accuracy: 0.9560 - val_loss: 0.3679 - val_accuracy: 0.9561\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3592 - accuracy: 0.9560 - val_loss: 0.3664 - val_accuracy: 0.9561\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3577 - accuracy: 0.9560 - val_loss: 0.3648 - val_accuracy: 0.9561\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3562 - accuracy: 0.9560 - val_loss: 0.3634 - val_accuracy: 0.9561\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3548 - accuracy: 0.9560 - val_loss: 0.3619 - val_accuracy: 0.9561\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3533 - accuracy: 0.9560 - val_loss: 0.3604 - val_accuracy: 0.9561\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3519 - accuracy: 0.9560 - val_loss: 0.3589 - val_accuracy: 0.9649\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.9560 - val_loss: 0.3574 - val_accuracy: 0.9649\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3490 - accuracy: 0.9560 - val_loss: 0.3558 - val_accuracy: 0.9649\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3475 - accuracy: 0.9560 - val_loss: 0.3542 - val_accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliar modelo"
      ],
      "metadata": {
        "id": "J37Nx3UAA58X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo nos dados de teste\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "# Avaliação do modelo usando a função evaluate() do Keras\n",
        "# Passamos os dados de teste X_test e os rótulos y_test\n",
        "# A função evaluate() retorna a perda (loss) e a acurácia calculadas no conjunto de teste\n",
        "# Os valores de perda e acurácia são armazenados nas variáveis loss e accuracy, respectivamente\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)\n",
        "# Impressão dos resultados da avaliação na tela\n",
        "# Imprimimos a perda (loss) e a acurácia (accuracy) obtidas nos dados de teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZXBxDQ3tuXo",
        "outputId": "b5602a3d-5851-4dc3-b890-a3f521456f0c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.9649\n",
            "Test Loss: 0.3542329668998718\n",
            "Test Accuracy: 0.9649122953414917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plota os valores"
      ],
      "metadata": {
        "id": "zK2GMVGHBWvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento do modelo e obtenção do histórico\n",
        "#history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
        "# Treinamento do modelo usando a função fit() do Keras\n",
        "# Passamos os dados de treinamento X_train e os rótulos y_train\n",
        "# Definimos o número de épocas como 10, o tamanho do lote como 32\n",
        "# Usamos os dados de teste (X_test, y_test) como conjunto de validação para avaliar o desempenho durante o treinamento\n",
        "# O histórico do treinamento é armazenado na variável history\n",
        "# Obtendo as métricas de treinamento\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "# Extração das métricas de treinamento do histórico\n",
        "# As métricas de acurácia de treinamento são armazenadas em train_acc\n",
        "# As métricas de acurácia de validação são armazenadas em val_acc\n",
        "# A variável epochs contém o número de épocas correspondente às métricas\n",
        "# Plotar o gráfico de tendência\n",
        "plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "#plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# Plotagem do gráfico de tendência da acurácia de treinamento e validação ao longo das épocas\n",
        "# Usamos a função plot() do matplotlib para plotar as curvas\n",
        "# Definimos a cor ('b' para azul) e rótulos ('Training Accuracy' e 'Validation Accuracy') para as curvas\n",
        "# Definimos título, rótulos dos eixos e legendas do gráfico\n",
        "# Usamos a função show() para exibir o gráfico\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "yWceYXMiuVsY",
        "outputId": "14404eac-62c4-4c3e-f44e-1dc4bdf3c5ea"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtVElEQVR4nO3dd1hTZxsG8DussAQUkOEARepWrCh1VVupOOrnqlVcSB21Vavi3qstVq3iqna46q5V6bAOitu66kCtShU3CioqSwEJ7/fHkdQIKIEkB8j9u65cJG/Oec+TI5rHdyqEEAJERERERsRE7gCIiIiIDI0JEBERERkdJkBERERkdJgAERERkdFhAkRERERGhwkQERERGR0mQERERGR0mAARERGR0WECREREREaHCRBRIfXt2xeenp4FOnfatGlQKBS6DaiIuX79OhQKBVatWmXwaysUCkybNk39etWqVVAoFLh+/fprz/X09ETfvn11Gk9hfleISLeYAFGJpVAo8vXYt2+f3KEavc8++wwKhQJXrlzJ85iJEydCoVDg7NmzBoxMe3fu3MG0adNw5swZuUPJ1cWLF6FQKGBpaYnHjx/LHQ6RbJgAUYm1Zs0ajcd7772Xa3n16tULdZ3vv/8e0dHRBTp30qRJePr0aaGuXxL07NkTALB+/fo8j9mwYQNq166NOnXqFPg6vXv3xtOnT+Hh4VHgOl7nzp07mD59eq4JUGF+V3Rl7dq1cHV1BQD8/PPPssZCJCczuQMg0pdevXppvD569CgiIiJylL/syZMnsLa2zvd1zM3NCxQfAJiZmcHMjH8N/fz8UKVKFWzYsAFTpkzJ8f6RI0dw7do1zJo1q1DXMTU1hampaaHqKIzC/K7oghAC69evR48ePXDt2jWsW7cO/fv3lzWmvKSmpsLGxkbuMKgEYwsQGbUWLVqgVq1aOHnyJN5++21YW1tjwoQJAIBffvkF7dq1g7u7O5RKJby8vDBz5kyoVCqNOl4e15E95mXu3Ln47rvv4OXlBaVSiQYNGuDEiRMa5+Y2BkihUGDIkCEIDw9HrVq1oFQqUbNmTezcuTNH/Pv27YOvry8sLS3h5eWFb7/9Nt/jig4ePIiuXbuiYsWKUCqVqFChAkaMGJGjRapv376wtbVFbGwsOnbsCFtbWzg7O2PUqFE57sXjx4/Rt29f2Nvbw8HBAUFBQfnuZunZsycuXbqEU6dO5Xhv/fr1UCgUCAwMREZGBqZMmYL69evD3t4eNjY2aNasGfbu3fvaa+Q2BkgIgc8//xzly5eHtbU13nnnHfzzzz85zn348CFGjRqF2rVrw9bWFnZ2dmjTpg2ioqLUx+zbtw8NGjQAAAQHB6u7WbPHP+U2Big1NRUjR45EhQoVoFQqUbVqVcydOxdCCI3jtPm9yMvhw4dx/fp1dO/eHd27d8eBAwdw+/btHMdlZWVhwYIFqF27NiwtLeHs7IzWrVvj77//1jhu7dq1aNiwIaytrVG6dGm8/fbb2L17t0bML47Byvby+KrsP5f9+/fj008/RdmyZVG+fHkAwI0bN/Dpp5+iatWqsLKygqOjI7p27ZrrOK7Hjx9jxIgR8PT0hFKpRPny5dGnTx88ePAAKSkpsLGxwbBhw3Kcd/v2bZiamiI0NDSfd5JKAv7Xk4xeQkIC2rRpg+7du6NXr15wcXEBIP2jbGtri5CQENja2mLPnj2YMmUKkpKSMGfOnNfWu379eiQnJ+Pjjz+GQqHA7Nmz0blzZ1y9evW1LQGHDh3C1q1b8emnn6JUqVJYuHAhunTpgps3b8LR0REAcPr0abRu3Rpubm6YPn06VCoVZsyYAWdn53x97s2bN+PJkyf45JNP4OjoiOPHj2PRokW4ffs2Nm/erHGsSqVCQEAA/Pz8MHfuXPz555/4+uuv4eXlhU8++QSAlEh06NABhw4dwqBBg1C9enVs27YNQUFB+YqnZ8+emD59OtavX48333xT49o//fQTmjVrhooVK+LBgwf44YcfEBgYiAEDBiA5ORnLly9HQEAAjh8/Dh8fn3xdL9uUKVPw+eefo23btmjbti1OnTqFVq1aISMjQ+O4q1evIjw8HF27dkWlSpUQHx+Pb7/9Fs2bN8eFCxfg7u6O6tWrY8aMGZgyZQoGDhyIZs2aAQAaN26c67WFEPjf//6HvXv3ol+/fvDx8cGuXbswevRoxMbGYv78+RrH5+f34lXWrVsHLy8vNGjQALVq1YK1tTU2bNiA0aNHaxzXr18/rFq1Cm3atEH//v2RmZmJgwcP4ujRo/D19QUATJ8+HdOmTUPjxo0xY8YMWFhY4NixY9izZw9atWqV7/v/ok8//RTOzs6YMmUKUlNTAQAnTpzAX3/9he7du6N8+fK4fv06li5dihYtWuDChQvq1tqUlBQ0a9YMFy9exEcffYQ333wTDx48wK+//orbt2/Dx8cHnTp1wqZNmzBv3jyNlsANGzZACKHuiiUjIYiMxODBg8XLv/LNmzcXAMSyZctyHP/kyZMcZR9//LGwtrYWaWlp6rKgoCDh4eGhfn3t2jUBQDg6OoqHDx+qy3/55RcBQPz222/qsqlTp+aICYCwsLAQV65cUZdFRUUJAGLRokXqsvbt2wtra2sRGxurLrt8+bIwMzPLUWducvt8oaGhQqFQiBs3bmh8PgBixowZGsfWq1dP1K9fX/06PDxcABCzZ89Wl2VmZopmzZoJAGLlypWvjalBgwaifPnyQqVSqct27twpAIhvv/1WXWd6errGeY8ePRIuLi7io48+0igHIKZOnap+vXLlSgFAXLt2TQghxL1794SFhYVo166dyMrKUh83YcIEAUAEBQWpy9LS0jTiEkL6s1YqlRr35sSJE3l+3pd/V7Lv2eeff65x3AcffCAUCoXG70B+fy/ykpGRIRwdHcXEiRPVZT169BB169bVOG7Pnj0CgPjss89y1JF9jy5fvixMTExEp06dctyTF+/jy/c/m4eHh8a9zf5zadq0qcjMzNQ4Nrff0yNHjggA4scff1SXTZkyRQAQW7duzTPuXbt2CQBix44dGu/XqVNHNG/ePMd5VLKxC4yMnlKpRHBwcI5yKysr9fPk5GQ8ePAAzZo1w5MnT3Dp0qXX1tutWzeULl1a/Tq7NeDq1auvPdff3x9eXl7q13Xq1IGdnZ36XJVKhT///BMdO3aEu7u7+rgqVaqgTZs2r60f0Px8qampePDgARo3bgwhBE6fPp3j+EGDBmm8btasmcZn+eOPP2BmZqZuEQKkMTdDhw7NVzyANG7r9u3bOHDggLps/fr1sLCwQNeuXdV1WlhYAJC6ah4+fIjMzEz4+vrm2n32Kn/++ScyMjIwdOhQjW7D4cOH5zhWqVTCxET6J1OlUiEhIQG2traoWrWq1tfN9scff8DU1BSfffaZRvnIkSMhhMCOHTs0yl/3e/EqO3bsQEJCAgIDA9VlgYGBiIqK0ujy27JlCxQKBaZOnZqjjux7FB4ejqysLEyZMkV9T14+piAGDBiQY4zWi7+nz549Q0JCAqpUqQIHBweN+75lyxbUrVsXnTp1yjNuf39/uLu7Y926der3zp8/j7Nnz752bCCVPEyAyOiVK1dO/YX6on/++QedOnWCvb097Ozs4OzsrP5HMjEx8bX1VqxYUeN1djL06NEjrc/NPj/73Hv37uHp06eoUqVKjuNyK8vNzZs30bdvX5QpU0Y9rqd58+YAcn6+7HEgecUDSGM13NzcYGtrq3Fc1apV8xUPAHTv3h2mpqbq2WBpaWnYtm0b2rRpo5FMrl69GnXq1IGlpSUcHR3h7OyM7du35+vP5UU3btwAAHh7e2uUOzs7a1wPkJKt+fPnw9vbG0qlEk5OTnB2dsbZs2e1vu6L13d3d0epUqU0yrNnJmbHl+11vxevsnbtWlSqVAlKpRJXrlzBlStX4OXlBWtra42EICYmBu7u7ihTpkyedcXExMDExAQ1atR47XW1UalSpRxlT58+xZQpU9RjpLLv++PHjzXue0xMDGrVqvXK+k1MTNCzZ0+Eh4fjyZMnAKRuQUtLS3WCTcaDCRAZvRf/h5nt8ePHaN68OaKiojBjxgz89ttviIiIwFdffQVA+jJ8nbxmG4mXBrfq+tz8UKlUeO+997B9+3aMHTsW4eHhiIiIUA/WffnzGWrmVNmyZfHee+9hy5YtePbsGX777TckJydrjM1Yu3Yt+vbtCy8vLyxfvhw7d+5EREQE3n333Xz9uRTUl19+iZCQELz99ttYu3Ytdu3ahYiICNSsWVOv131RQX8vkpKS8Ntvv+HatWvw9vZWP2rUqIEnT55g/fr1Ovvdyo+XB89ny+3v4tChQ/HFF1/gww8/xE8//YTdu3cjIiICjo6OBbrvffr0QUpKCsLDw9Wz4t5//33Y29trXRcVbxwETZSLffv2ISEhAVu3bsXbb7+tLr927ZqMUf2nbNmysLS0zHXhwFctJpjt3Llz+Pfff7F69Wr06dNHXR4REVHgmDw8PBAZGYmUlBSNViBt173p2bMndu7ciR07dmD9+vWws7ND+/bt1e///PPPqFy5MrZu3arR3ZJbl01+YgaAy5cvo3Llyury+/fv52hV+fnnn/HOO+9g+fLlGuWPHz+Gk5OT+rU2XUAeHh74888/kZycrNEKlN3Fqqv1irZu3Yq0tDQsXbpUI1ZA+vOZNGkSDh8+jKZNm8LLywu7du3Cw4cP82wF8vLyQlZWFi5cuPDKQeelS5fOMQswIyMDd+/ezXfsP//8M4KCgvD111+ry9LS0nLU6+XlhfPnz7+2vlq1aqFevXpYt24dypcvj5s3b2LRokX5jodKDrYAEeUi+3/aL/6vOCMjA998841cIWkwNTWFv78/wsPDcefOHXX5lStXcowbyet8QPPzCSGwYMGCAsfUtm1bZGZmYunSpeoylUql9ZdLx44dYW1tjW+++QY7duxA586dYWlp+crYjx07hiNHjmgds7+/P8zNzbFo0SKN+sLCwnIca2pqmqOVZPPmzYiNjdUoy167Jj/T/9u2bQuVSoXFixdrlM+fPx8KhSLf47leZ+3atahcuTIGDRqEDz74QOMxatQo2NraqrvBunTpAiEEpk+fnqOe7M/fsWNHmJiYYMaMGTlaYV68R15eXhrjuQDgu+++y7MFKDe53fdFixblqKNLly6IiorCtm3b8ow7W+/evbF7926EhYXB0dFRZ/eZihe2ABHlonHjxihdujSCgoLU2zSsWbPGoN0ErzNt2jTs3r0bTZo0wSeffKL+Iq1Vq9Zrt2GoVq0avLy8MGrUKMTGxsLOzg5btmzJ11iSvLRv3x5NmjTBuHHjcP36ddSoUQNbt27VenyMra0tOnbsqB4H9PLU5Pfffx9bt25Fp06d0K5dO1y7dg3Lli1DjRo1kJKSotW1stczCg0Nxfvvv4+2bdvi9OnT2LFjR46Wkvfffx8zZsxAcHAwGjdujHPnzmHdunUaLUeA9KXv4OCAZcuWoVSpUrCxsYGfn1+u41vat2+Pd955BxMnTsT169dRt25d7N69G7/88guGDx+uMeC5oO7cuYO9e/fmGGidTalUIiAgAJs3b8bChQvxzjvvoHfv3li4cCEuX76M1q1bIysrCwcPHsQ777yDIUOGoEqVKpg4cSJmzpyJZs2aoXPnzlAqlThx4gTc3d3V6+n0798fgwYNQpcuXfDee+8hKioKu3btynFvX+X999/HmjVrYG9vjxo1auDIkSP4888/c0z7Hz16NH7++Wd07doVH330EerXr4+HDx/i119/xbJly1C3bl31sT169MCYMWOwbds2fPLJJ7IvUEkyMfCsMyLZ5DUNvmbNmrkef/jwYfHWW28JKysr4e7uLsaMGaOeRrt37171cXlNg58zZ06OOvHStOC8psEPHjw4x7kvTx0WQojIyEhRr149YWFhIby8vMQPP/wgRo4cKSwtLfO4C/+5cOGC8Pf3F7a2tsLJyUkMGDBAPa36xSncQUFBwsbGJsf5ucWekJAgevfuLezs7IS9vb3o3bu3OH36dL6nwWfbvn27ACDc3NxynWb95ZdfCg8PD6FUKkW9evXE77//nuPPQYjXT4MXQgiVSiWmT58u3NzchJWVlWjRooU4f/58jvudlpYmRo4cqT6uSZMm4siRI6J58+Y5plD/8ssvokaNGuolCbI/e24xJicnixEjRgh3d3dhbm4uvL29xZw5czSmk2d/lvz+Xrzo66+/FgBEZGRknsesWrVKABC//PKLEEJaamDOnDmiWrVqwsLCQjg7O4s2bdqIkydPapy3YsUKUa9ePaFUKkXp0qVF8+bNRUREhPp9lUolxo4dK5ycnIS1tbUICAgQV65cyXMa/IkTJ3LE9ujRIxEcHCycnJyEra2tCAgIEJcuXcr1cyckJIghQ4aIcuXKCQsLC1G+fHkRFBQkHjx4kKPetm3bCgDir7/+yvO+UMmmEKII/ZeWiAqtY8eO+Oeff3D58mW5QyEqsjp16oRz587la8wclUwcA0RUjL28bcXly5fxxx9/oEWLFvIERFQM3L17F9u3b0fv3r3lDoVkxBYgomLMzc0Nffv2ReXKlXHjxg0sXboU6enpOH36dI61bYiM3bVr13D48GH88MMPOHHiBGJiYuDq6ip3WCQTDoImKsZat26NDRs2IC4uDkqlEo0aNcKXX37J5IcoF/v370dwcDAqVqyI1atXM/kxcmwBIiIiIqPDMUBERERkdJgAERERkdHhGKBcZGVl4c6dOyhVqlShdjYmIiIiwxFCIDk5Ge7u7jAxeXUbDxOgXNy5cwcVKlSQOwwiIiIqgFu3bqF8+fKvPIYJUC6yNyW8desW7OzsZI6GiIiI8iMpKQkVKlTQ2Fw4L0yAcpHd7WVnZ8cEiIiIqJjJz/AVDoImIiIio8MEiIiIiIwOEyAiIiIyOhwDVAgqlQrPnj2TOwwinTM3N4epqancYRAR6Q0ToAIQQiAuLg6PHz+WOxQivXFwcICrqyvXwiKiEokJUAFkJz9ly5aFtbU1vyCoRBFC4MmTJ7h37x4Aacd5IqKShgmQllQqlTr5cXR0lDscIr2wsrICANy7dw9ly5ZldxgRlTgcBK2l7DE/1tbWMkdCpF/Zv+Mc50ZEJREToAJitxeVdPwdJ6KSjAkQERERGR0mQFRgnp6eCAsLy/fx+/btg0Kh4Ow5IiKSHRMgI6BQKF75mDZtWoHqPXHiBAYOHJjv4xs3boy7d+/C3t6+QNcriGrVqkGpVCIuLs5g1yQioqKPs8CMwN27d9XPN23ahClTpiA6OlpdZmtrq34uhIBKpYKZ2et/NZydnbWKw8LCAq6urlqdUxiHDh3C06dP8cEHH2D16tUYO3aswa6dm2fPnsHc3FzWGIiIdColBUhIKNi5dnZA6dK6jUcLbAEyAq6uruqHvb09FAqF+vWlS5dQqlQp7NixA/Xr14dSqcShQ4cQExODDh06wMXFBba2tmjQoAH+/PNPjXpf7gJTKBT44Ycf0KlTJ1hbW8Pb2xu//vqr+v2Xu8BWrVoFBwcH7Nq1C9WrV4etrS1at26tkbBlZmbis88+g4ODAxwdHTF27FgEBQWhY8eOr/3cy5cvR48ePdC7d2+sWLEix/u3b99GYGAgypQpAxsbG/j6+uLYsWPq93/77Tc0aNAAlpaWcHJyQqdOnTQ+a3h4uEZ9Dg4OWLVqFQDg+vXrUCgU2LRpE5o3bw5LS0usW7cOCQkJCAwMRLly5WBtbY3atWtjw4YNGvVkZWVh9uzZqFKlCpRKJSpWrIgvvvgCAPDuu+9iyJAhGsffv38fFhYWiIyMfO09ISLSmZgYwM0N8PQs2GPOHDmiVmMCpANCAKmphn8IobvPMG7cOMyaNQsXL15EnTp1kJKSgrZt2yIyMhKnT59G69at0b59e9y8efOV9UyfPh0ffvghzp49i7Zt26Jnz554+PBhnsc/efIEc+fOxZo1a3DgwAHcvHkTo0aNUr//1VdfYd26dVi5ciUOHz6MpKSkHIlHbpKTk7F582b06tUL7733HhITE3Hw4EH1+ykpKWjevDliY2Px66+/IioqCmPGjEFWVhYAYPv27ejUqRPatm2L06dPIzIyEg0bNnztdV82btw4DBs2DBcvXkRAQADS0tJQv359bN++HefPn8fAgQPRu3dvHD9+XH3O+PHjMWvWLEyePBkXLlzA+vXr4eLiAgDo378/1q9fj/T0dPXxa9euRbly5fDuu+9qHR8RUYHNnSu1AJmaApaW2j/y0dOgV4JySExMFABEYmJijveePn0qLly4IJ4+faouS0kRQkpHDPtISdH+s61cuVLY29urX+/du1cAEOHh4a89t2bNmmLRokXq1x4eHmL+/Pnq1wDEpEmTXrgvKQKA2LFjh8a1Hj16pI4FgLhy5Yr6nCVLlggXFxf1axcXFzFnzhz168zMTFGxYkXRoUOHV8b63XffCR8fH/XrYcOGiaCgIPXrb7/9VpQqVUokJCTken6jRo1Ez54986wfgNi2bZtGmb29vVi5cqUQQohr164JACIsLOyVcQohRLt27cTIkSOFEEIkJSUJpVIpvv/++1yPffr0qShdurTYtGmTuqxOnTpi2rRpr72OtnL7XSciEkIIER8vhKWl9GW0f7/c0ai96vv7ZWwBIgCAr6+vxuuUlBSMGjUK1atXh4ODA2xtbXHx4sXXtgDVqVNH/dzGxgZ2dnbqLRVyY21tDS8vL/VrNzc39fGJiYmIj4/XaHkxNTVF/fr1X/t5VqxYgV69eqlf9+rVC5s3b0ZycjIA4MyZM6hXrx7KlCmT6/lnzpxBy5YtX3ud13n5vqpUKsycORO1a9dGmTJlYGtri127dqnv68WLF5Genp7ntS0tLTW69E6dOoXz58+jb9++hY6ViCjfvvkGSEsDGjQAmjWTO5oC4SBoHbC2lloB5biurtjY2Gi8HjVqFCIiIjB37lxUqVIFVlZW+OCDD5CRkfHKel4e5KtQKNTdSvk9XhSyb+/ChQs4evQojh8/rjHwWaVSYePGjRgwYIB6q4e8vO793OLMbcXkl+/rnDlzsGDBAoSFhaF27dqwsbHB8OHD1ff1ddcFpG4wHx8f3L59GytXrsS7774LDw+P155HRKQTT54AixdLz0ePBorpoqlsAdIBhQKwsTH8Q5+/c4cPH0bfvn3RqVMn1K5dG66urrh+/br+LpgLe3t7uLi44MSJE+oylUqFU6dOvfK85cuX4+2330ZUVBTOnDmjfoSEhGD58uUApJaqM2fO5Dk+qU6dOq8cVOzs7KwxWPvy5ct48uTJaz/T4cOH0aFDB/Tq1Qt169ZF5cqV8e+//6rf9/b2hpWV1SuvXbt2bfj6+uL777/H+vXr8dFHH732ukREOrN6tTTzq1Il4IXJIcUNEyDKlbe3N7Zu3YozZ84gKioKPXr0eGVLjr4MHToUoaGh+OWXXxAdHY1hw4bh0aNHeW7T8OzZM6xZswaBgYGoVauWxqN///44duwY/vnnHwQGBsLV1RUdO3bE4cOHcfXqVWzZsgVHjhwBAEydOhUbNmzA1KlTcfHiRZw7dw5fffWV+jrvvvsuFi9ejNOnT+Pvv//GoEGD8jXF3dvbGxEREfjrr79w8eJFfPzxx4iPj1e/b2lpibFjx2LMmDH48ccfERMTg6NHj6oTt2z9+/fHrFmzIITQmJ1GRKRXKhXw9dfS85AQ+QcyFwITIMrVvHnzULp0aTRu3Bjt27dHQEAA3nzzTYPHMXbsWAQGBqJPnz5o1KgRbG1tERAQAEtLy1yP//XXX5GQkJBrUlC9enVUr14dy5cvh4WFBXbv3o2yZcuibdu2qF27NmbNmqXe9bxFixbYvHkzfv31V/j4+ODdd9/VmKn19ddfo0KFCmjWrBl69OiBUaNG5WuD3EmTJuHNN99EQEAAWrRooU7CXjR58mSMHDkSU6ZMQfXq1dGtW7cc46gCAwNhZmaGwMDAPO8FEZHOhYdL09/LlAGCg+WOplAUorADLkqgpKQk2NvbIzExEXZ2dhrvpaWl4dq1a6hUqRK/eGSQlZWF6tWr48MPP8TMmTPlDkc2169fh5eXF06cOKG3xJS/60SkQQigUSPg2DFg0iSgCP4b/Krv75cV37YrMgo3btzA7t270bx5c6Snp2Px4sW4du0aevToIXdosnj27BkSEhIwadIkvPXWW7K0yhFR4em16eH+fWmGlq5FRUFx7BiEUgkMHgLo4DPIOX6aCRAVaSYmJli1ahVGjRoFIQRq1aqFP//8E9WrV5c7NFkcPnwY77zzDt544w38/PPPcodDRFpKTQXmz5eG0ehjX+hBWIql+FT3Fb/g+/Q++NjNpdD1jB8PfPmlDgIqICZAVKRVqFABhw8fljuMIqNFixaFXiaAiAxPpQJWrQKmTAHu3NHPNcyRgUn4HACQAXNk6WGYbzxcMAvjdF6vHJgAERER6YkQwM6dwJgxwPnzUpmnJxAaCvj76/Zayo0bUGroHahc3ZF08hpgYaHbCwCwAXD8tUflTz6WPdMrJkBERER6cOqUlPhkL+tVurQ0dnjwYECp1PHFhAC+nQsAMB0xDE7uuk9+ShrZp8EvWbIEnp6esLS0hJ+fn8ZU45c9e/YMM2bMgJeXFywtLVG3bl3s3LlT45hp06ZBoVBoPKpVq6bvj0FERAQAuHkT6N0bqF9fSn4sLICRI6XZ4yEhekh+AGDXLqmJydYWGDhQDxcoeWRtAdq0aRNCQkKwbNky+Pn5ISwsDAEBAYiOjkbZsmVzHD9p0iSsXbsW33//PapVq4Zdu3ahU6dO+Ouvv1CvXj31cTVr1sSff/6pfm1WjBdqIiIi/bp6FZg4EdiyBcjMLHx9Lw7TCwwEvvhCWjRZr+bMkX4OHAg4OOj5YiWDrC1A8+bNw4ABAxAcHIwaNWpg2bJlsLa2Vm/0+LI1a9ZgwoQJaNu2LSpXroxPPvkEbdu2xdfZq1I+Z2ZmBldXV/XDycnJEB+HiIiKkYcPpRaZatWAjRuBZ8+k5KWwDwBo3hw4cQJYv94Ayc+pU8CePYCpKTBsmJ4vVnLI1jSSkZGBkydPYvz48eoyExMT+Pv7q7cjeFl6enqOBdmsrKxw6NAhjbLLly/D3d0dlpaWaNSoEUJDQ1GxYsU8Y0lPT0d6err6dVJSUkE+EhERFUF//w3s3g28uJtPUhLw/ff/TUX39wc+/xzQxb7C5uaAo2Ph68m3udLYH3TvDrziu440yZYAPXjwACqVCi4ummsJuLi44NKlS7meExAQgHnz5uHtt9+Gl5cXIiMjsXXrVqhUKvUxfn5+WLVqFapWrYq7d+9i+vTpaNasGc6fP49SpUrlWm9oaCimT5+uuw9XQrVo0QI+Pj4ICwsDAHh6emL48OEYPnx4nucoFAps27Ytx3YP2tJVPURkPK5eBSZMADZtyvuY2rWl3qOAAMPFpVM3bgA//SQ9HzVK3liKmWI1OGbBggUYMGAAqlWrBoVCAS8vLwQHB2t0mbVp00b9vE6dOvDz84OHhwd++ukn9OvXL9d6x48fj5CQEPXrpKQkVKhQQX8fxMDat2+PZ8+e5RgwDgAHDx5U75xep04dreo9ceIEbGxsdBUmAGkQe3h4OM6cOaNRfvfuXZQuXVqn18rL06dPUa5cOZiYmCA2NhZKvYxYJDKwhATg6VO5o9CPMmWAF/biS0iQxt0sXix1aykUQMeOgLOz5mlNmwI9ekg9R7lKT5dWVS7KvvpKWmTI3x/w8ZE7mmJFtgTIyckJpqamGjthA0B8fDxcXV1zPcfZ2Rnh4eFIS0tDQkIC3N3dMW7cOFSuXDnP6zg4OOCNN97AlStX8jxGqVSW6C+5fv36oUuXLrh9+zbKly+v8d7KlSvh6+urdfIDSH8ehpLX74Q+bNmyBTVr1oQQAuHh4ejWrZvBrv0yIQRUKhUH8lPhrFgB5PEfwJIgEXbwNYvCDYUnAGkgc/ZYnFatgNmzgbp1taz08WOgVi0gNlaXoerP6NFyR1DsyDYI2sLCAvXr10dk9gIJkDa6jIyMRKNGjV55rqWlJcqVK4fMzExs2bIFHTp0yPPYlJQUxMTEwM3NTWexFzfvv/8+nJ2dsWrVKo3ylJQUbN68Gf369UNCQgICAwNRrlw5WFtbo3bt2tiwYcMr6/X09FR3hwHS2Ku3334blpaWqFGjBiIiInKcM3bsWLzxxhuwtrZG5cqVMXnyZDx79gwAsGrVKkyfPh1RUVHqJQyyY1YoFAgPD1fXc+7cObz77ruwsrKCo6MjBg4ciJSUFPX7ffv2RceOHTF37ly4ubnB0dERgwcPVl/rVZYvX45evXqhV69eWL58eY73//nnH7z//vuws7NDqVKl0KxZM8TExKjfX7FiBWrWrAmlUgk3NzcMGTIEgLSBqUKh0Gjdevz4MRQKBfbt2wcA2LdvHxQKBXbs2IH69etDqVTi0KFDiImJQYcOHeDi4gJbW1s0aNBAY6YjII1lGzt2LCpUqAClUokqVapg+fLlEEKgSpUqmJs9TuC5M2fOQKFQvPI/B1QCZGYC2V38ZmbSnOwi8hAWFsg0tUA6Cv5QwQT2SMLQzHl49uy/gcx16kgzw3ftKkDyAwDffSclPwqF7PfptY/27YH33tPpr40xkPW/lSEhIQgKCoKvry8aNmyIsLAwpKamIjg4GADQp08flCtXDqGhoQCAY8eOITY2Fj4+PoiNjcW0adOQlZWFMWPGqOscNWoU2rdvDw8PD9y5cwdTp06FqakpAgMD9fdBhACePNFf/Xmxts7XTnJmZmbo06cPVq1ahYkTJ0Lx/JzNmzdDpVIhMDAQKSkpqF+/PsaOHQs7Ozts374dvXv3hpeXFxo2bPjaa2RlZaFz585wcXHBsWPHkJiYmOvYoFKlSmHVqlVwd3fHuXPnMGDAAJQqVQpjxoxBt27dcP78eezcuVP95W5vb5+jjtTUVAQEBKBRo0Y4ceIE7t27h/79+2PIkCEaSd7evXvh5uaGvXv34sqVK+jWrRt8fHwwYMCAPD9HTEwMjhw5gq1bt0IIgREjRuDGjRvweD4yMjY2Fm+//TZatGiBPXv2wM7ODocPH0bm87mzS5cuRUhICGbNmoU2bdogMTGxQFt5jBs3DnPnzkXlypVRunRp3Lp1C23btsUXX3wBpVKJH3/8Ee3bt0d0dLR6gH+fPn1w5MgRLFy4EHXr1sW1a9fw4MEDKBQKfPTRR1i5ciVGvTBGYOXKlXj77bdRpUoVreOjYmTzZmlhGmdnabyI3MvvQuqxWbtWWhTw9m2p7M03gVmzgBo1tKtLeSgSTt39McRqOboen4qs0o4wMQFcXQux0WZGBrBggfR85UogKKiAFVGRJmS2aNEiUbFiRWFhYSEaNmwojh49qn6vefPmIigoSP163759onr16kKpVApHR0fRu3dvERsbq1Fft27dhJubm7CwsBDlypUT3bp1E1euXNEqpsTERAFAJCYm5njv6dOn4sKFC+Lp06f/Faak6GLmpPaPlJR8f6aLFy8KAGLv3r3qsmbNmolevXrleU67du3EyJEj1a+bN28uhg0bpn7t4eEh5s+fL4QQYteuXcLMzEzjz2PHjh0CgNi2bVue15gzZ46oX7+++vXUqVNF3bp1cxz3Yj3fffedKF26tEh54fNv375dmJiYiLi4OCGEEEFBQcLDw0NkZmaqj+natavo1q1bnrEIIcSECRNEx44d1a87dOggpk6dqn49fvx4UalSJZGRkZHr+e7u7mLixIm5vnft2jUBQJw+fVpd9ujRI40/l7179woAIjw8/JVxCiFEzZo1xaJFi4QQQkRHRwsAIiIiItdjY2NjhampqTh27JgQQoiMjAzh5OQkVq1alWf9uf6uU/GSlSXEm29K/15Mny53NEIIIXbtEqJu3f/+GatYUYi1a4VQqQpYYVaWED4+UmWff66bIFetkupzdxciPV03dZJBvOr7+2WyDywYMmSIuovgZdndAtmaN2+OCxcuvLK+jRs36iq0EqVatWpo3LgxVqxYgRYtWuDKlSs4ePAgZsyYAQBQqVT48ssv8dNPPyE2NhYZGRlIT0+H9QsDC1/l4sWLqFChAtzd3dVluXVlbtq0CQsXLkRMTAxSUlKQmZkJOzs7rT7LxYsXUbduXY0B2E2aNEFWVhaio6PVMwtr1qwJ0xdGN7q5ueHcuXN51qtSqbB69WosyP6fH4BevXph1KhRmDJlCkxMTHDmzBk0a9YM5ubmOc6/d+8e7ty5g5YtW2r1eXLj6+ur8TolJQXTpk3D9u3bcffuXWRmZuLp06e4efMmAKk7y9TUFM2bN8+1Pnd3d7Rr1w4rVqxAw4YN8dtvvyE9PR1du3YtdKxUhO3dK60RY2UFfKrfHcJfJypK2hZi927ptb29tPjg0KHAS6ubaEehkMa/9OwJLFokLblcmAqF+G9a+bBhetlPi4oG2bfCKBGsrYGUFMM/8pmcZOvXrx+2bNmC5ORkrFy5El5eXuovzDlz5mDBggUYO3Ys9u7dizNnziAgIAAZGRk6u01HjhxBz5490bZtW/z+++84ffo0Jk6cqNNrvOjlJEWhUCDrxYVAXrJr1y7ExsaiW7duMDMzg5mZGbp3744bN26ox6pZvaL74FXvAdI6VwA0dnPPa0zSy7PrRo0ahW3btuHLL7/EwYMHcebMGdSuXVt97153bQDo378/Nm7ciKdPn2LlypXo1q1bvhNcKqayVwcODgYKuSBsRgYQFgaULy/lU9o+fHyk5MfcHBg+XNoWYvToQiY/2bp2BSpUAOLjgTVrClfXzp3cUsJIMAHSBYUCsLEx/EPLDu4PP/wQJiYmWL9+PX788Ud89NFH6vFAhw8fRocOHdCrVy/UrVsXlStXxr///pvvuqtXr45bt27h7t276rKjR49qHPPXX3/Bw8MDEydOhK+vL7y9vXHjxg2NYywsLDTWdcrrWlFRUUhNTVWXHT58GCYmJqhatWq+Y37Z8uXL0b17d5w5c0bj0b17d/Vg6Dp16uDgwYO5Ji6lSpWCp6enxsD+F2XPmnvxHr083T8vhw8fRt++fdGpUyfUrl0brq6uuH79uvr92rVrIysrC/v378+zjrZt28LGxgZLly7Fzp078dFHH+Xr2lRMnT8vfZkrFNJyxwUkhLSOTvXqwIgR0rjgtDTtHwDw4YfAxYvA/Pk6XijQ3FwKDgC+/lpzxUNtZbf+cEuJEo8JkBGxtbVFt27dMH78eNy9exd9+/ZVv+ft7Y2IiAj89ddfuHjxIj7++OMcSxS8ir+/P9544w0EBQUhKioKBw8exMSJEzWO8fb2xs2bN7Fx40bExMRg4cKF2LZtm8Yxnp6euHbtGs6cOYMHDx5orNCdrWfPnrC0tERQUBDOnz+PvXv3YujQoejdu3eOhTXz6/79+/jtt98QFBSEWrVqaTz69OmD8PBwPHz4EEOGDEFSUhK6d++Ov//+G5cvX8aaNWsQHR0NQFrH6Ouvv8bChQtx+fJlnDp1CosWLQIgtdK89dZbmDVrFi5evIj9+/dj0qRJ+YrP29sbW7duxZkzZxAVFYUePXpotGZ5enoiKCgIH330EcLDw3Ht2jXs27cPP2UvkAbA1NQUffv2xfjx4+Ht7f3a2ZZUzGV/kXfuDHh5FaiKgweBt96SFhi+elUaWPzdd8D169o/7t+XEqkChvJ6/ftL/WrR0cDvvxesDm4pYVz0PySp+NF6EHQx8tdffwkAom3bthrlCQkJokOHDsLW1laULVtWTJo0SfTp00d06NBBfcyrBkELIQ3Ebdq0qbCwsBBvvPGG2LlzZ45B0KNHjxaOjo7C1tZWdOvWTcyfP1/Y29ur309LSxNdunQRDg4OAoBYuXKlEELkqOfs2bPinXfeEZaWlqJMmTJiwIABIjk5Wf1+UFCQRuxCCDFs2DDRvHnzXO/L3LlzhYODQ66Dm9PT04WDg4NYsGCBEEKIqKgo0apVK2FtbS1KlSolmjVrJmJiYtTHL1u2TFStWlWYm5sLNzc3MXToUPV7Fy5cEI0aNRJWVlbCx8dH7N69O9dB0I8ePdKI4dq1a+Kdd94RVlZWokKFCmLx4sU5/jyePn0qRowYoZ4EUKVKFbFixQqNemJiYgQAMXv27Fzvw4uK+++6Ubt9Wwhzc2kg7wsTS/Lr0iUhOnT4b6CyjY0Q06YJ8cJfsaJp7Fgp4GbNCnZ+YKB0fs+euo2LDEabQdAKIV7ct5YAaSVoe3t7JCYm5higm5aWhmvXrqFSpUo59iUjKuoOHjyIli1b4tatW69tLePvup5lZQFxcZpbh+vKnDnSNO6mTaVmnHy6dw+YNk1q5VGpABMTqWFl+nSp9afIu3MH8PSUFgPauVNayDC/4uOBhg2lD376NFdVLqZe9f39MtlngRGR/qWnp+P+/fuYNm0aunbtWuCuQtKh//0P2L5dv9cYPRqPHgFffgmsWvXfWJy8pKVJ6yYC0tp6X30ljf0pNtzdpdlgq1YBrVsXrA5uKWE0mAARGYENGzagX79+8PHxwY8//ih3OHT06H/Jj562Oclq8S4WXH4fM/sCjx7l/zxfX6kBqUULvYSlfxMmSNPN7t3T/lw7O+D50iBU8jEBIjICffv21Rj0TjLLHqDct6+00nA+ZWYC27b9t3pyXtLTpW6sa88X/q5ZEwgNlX6+ipmZNJu8wCsoFwXe3sVn/y6SFRMgIiJDunIF2LpVej5yZL5OEUKa2DR2rDSNPL/c3KQGjb599dbQRFRs8a9EAXHsOJV0/B3Xk/nzpYymTZt8DdI9cUJaMDB7iSdHRyAg4PWtNHXqAIMHS0uGEVFOTIC0lL268JMnT/K1+i5RcfXk+Qa/uW37QdrZt09aVy8z7gHOJ6+ENYD/HRiFAw6vPzcxUfqpVEorKI8bx/X5iHSBCZCWTE1N4eDggHvPB9hZW1urV1MmKgmEEHjy5Anu3bsHBwcHjf3USHunT0sTvpKTgcn4BtZ4ipN4E7+lvpPvOnr3Bj7/HKhYUY+BEhkZJkAF4Pp8QYx7BZllQFRMODg4qH/XqWBiYqSeruRkoFWzp5jyz2LgIeA+bzSi2+XvP0729gBXLSDSPSZABaBQKODm5oayZcvmuZklUXFmbm7Olp9CiosDWrWS1tfz8QHCO/8Is4P3AQ8PuA39AG7815dIVvwrWAimpqb8kiAyNs+eAQ8evPKQ5GSgd2fgyVXAryLw60oBqw+/lt4cMYJTsoiKAP4tJCLKr5QUoHZtaXfPVygFICL7xU0A9Z4/d3AA+vXTV3REpAUmQERE+bV8uTr5yTIxRVbWqw83NQXUI33MzaVNtWxt9RkhEeUTEyAiojzcuSPtWPHsGaBQZaLnjPmwAzDNZSmmxw8CIC08/PnnUsPQiypW5Bo8REUZEyAiopckJwOzZwNffw08fSqVdcPP+AQ3cB9O+Co+CE5OwNSpwMcfS407RFS8MAEiInru2TPg+++BadOA+/elsvr1gUqeAl9GzgEeA3tqDMH4blYYNkyaok5ExRMTICIyekIAv/4q7bUVHS2VeXsDX30FdOwIKPbtA7acAqys0G3/YMBJzmiJSBeYABGRUTt2TNpr6+BB6bWTk9QCNHDgC11bc+ZIP4ODpQOIqNhjAkREJZ4QwK5dwI0bmuV79gA//SQ9t7QEQkKkViA7uxcOOn8e2LFD2n10xAiDxUxE+sUEiIhKvHHjpEHNuVEogKAgYOZMoHz5XA74+vkChp07A1Wq6C1GIjIsJkBEVKLNmyclP1Z4gs4tk2Bh8d979vZA//5AzZrPC+JeOjkhAVi3Tno+apQhwiUiA2ECRERF0pMnQFgYsGLFf1PR82JmBnToAEyeDDg7/1e+di0wciRQC+dwytwP5pG5VLQxH8E0bQq89ZY24RNREccEiIiKFJUKWLMGmDQJiI3N/3mLFgGrV0vdXcOHA/v2SWOWAWBV1VCYRz9PfkxMtAvI1lbqHyOiEkUhhBByB1HUJCUlwd7eHomJibDTGA1JRPq0e7c0I+vsWem1h4eUe7y8yvLLbt8GpkwBTp+WXpcvDzx8KLUifdbhBsJ+94JCpQJOnQLq1Xt1ZURUbGnz/c0WICKSXVSUlPhEPN9B1MEBmDgRGDJEmp31Oj4+QNu2wPr10nk3b0rlrVoB8yqGSclPy5ZMfohIjQkQEcnm1i1p3M6PP0pT1c3NpaRn4kTA0VG7ukxMgF69gA8+AJYulaa8fz7yEUyrfy8dMHq07j8AERVbTICIqMCEkNbRmT37v60jtBEfD2RkSM+7dQO+/BKoXLlwMVlavrBcz6xvgdRUqQ+tVavCVUxEJQoTICIqkAMHpJnhJ04Urp5mzYC5c4GGDXUTl1p6OrBggfR81ChpwR8ioueYABGR2tmz0jjhVxEC+OUX6QEANjbAmDFAmzba5xg2NkC1anrKTdavB+LigHLlgO7d9XABIirOmAAREa5fByZMADZsyP85pqbAgAHSvlkuLvqKrICysqRmJQAYNgwaqx8SEYEJEJFRe/QI+OILaQ2djAypJaZ5c8Da+tXnubpKvUrVq+sggOxBQLq0fz9w4QJQqpS0qykR0UuYABHpWHo68M03wA8/vH4FY7ndvw+kpEjP/f2lwcwGmyk+Z47Ud6ZPAwdK+10QEb2ECRCRjmTPiBo/Hrh2Te5o8q9WLSkXCQgw4DjhlBQgNFS/1/Dw4O7tRJQnJkBEOnDwoNQldPy49NrNTRobU7eurGG9llIpzRA3NTXwhVeskLq/qlQBLl2SIQAiMnZMgIgK4dIlYOxY4Ndfpdc2NtLrkBDpOeUiMxOYP196PnIkkx8ikgUTIKICiI+XWni+/17avLNIz4gqarZskaadOTkBQUFyR0NERooJENFzDx9Kw1J++01Kal7lzh1po00A+N//gFmzdDAjyhgIIQ04AqQ9L6ys5I2HiIwWEyAyeunpwOLF0nTwR4/yf16DBtJ3efPm+outxNm/Hzh5Utqv4tNP5Y6GiIwYEyAyWllZwKZN0gKA169LZbVqAVOnSoOYX8XaWhrgbGKi9zBLluzFCYODAWdneWMhIqPGBIiM0v790qytv/+WXru7AzNnSkNSOCZXTy5cALZvl+bac3o6EcmMCRAZlYsXpVlav/0mvba1/W/W1utWPy7SMjKAxES5o3i1r76SfnbqBHh7yxsLERk9JkBkFOLipBlaP/zw36ytjz+WurvKlpU7ukKKj5f64+Lj5Y4kf0aNkjsCIiLIPoJhyZIl8PT0hKWlJfz8/HA8eyW5XDx79gwzZsyAl5cXLC0tUbduXezcubNQdVLJlpoKzJghrbf37bdS8tOxI/DPP8CSJSUg+QGkjbyKS/Lz4YdAo0ZyR0FEBAgZbdy4UVhYWIgVK1aIf/75RwwYMEA4ODiI+Pj4XI8fM2aMcHd3F9u3bxcxMTHim2++EZaWluLUqVMFrjM3iYmJAoBITEws9GckeTx7JsT33wvh5iaENPdaCD8/IQ4ckDsyHUtOFqJ0aekDbtkidzRERLLS5vtb1gSoYcOGYvDgwerXKpVKuLu7i9DQ0FyPd3NzE4sXL9Yo69y5s+jZs2eB68wNE6DiKytLiN9/F6Jmzf8Sn8qVhdi0SXqvxFm4UPqQVaoIkZkpdzRERLLS5vtbti6wjIwMnDx5Ev7+/uoyExMT+Pv748iRI7mek56eDktLS40yKysrHDp0qMB1ZteblJSk8aDi5+RJoGVL4P33pS6uMmWkHRcuXJB6Xgy20aehZGYC8+ZJz7mlBBGRVmRLgB48eACVSgWXl/YNcHFxQVxcXK7nBAQEYN68ebh8+TKysrIQERGBrVu34u7duwWuEwBCQ0Nhb2+vflSoUKGQn44MKStLWlTY1xfYu1fa4HP0aCAmBhg+XHpdIm3dyi0liIgKSPZB0NpYsGABvL29Ua1aNVhYWGDIkCEIDg6GSSFXoxs/fjwSExPVj1u3bukoYtI3IaTGjyVLpNe9egHR0cDs2YCDg6yh6Re3lCAiKhTZEiAnJyeYmpoi/qXZK/Hx8XB1dc31HGdnZ4SHhyM1NRU3btzApUuXYGtri8qVKxe4TgBQKpWws7PTeFDxMHs2EBYmPV+zRnp4eMgakmEcOCCt4sgtJYiICkS2BMjCwgL169dHZGSkuiwrKwuRkZFo9JppspaWlihXrhwyMzOxZcsWdOjQodB1UvGzciUwbpz0fN48qfXHaGS3/nBLCSKiApF1IcSQkBAEBQXB19cXDRs2RFhYGFJTUxEcHAwA6NOnD8qVK4fQ0FAAwLFjxxAbGwsfHx/ExsZi2rRpyMrKwpgxY/JdJ5UMv/0GDBggPR8zphA7K6SlASkpOovLIGJiuKUEEVEhyZoAdevWDffv38eUKVMQFxcHHx8f7Ny5Uz2I+ebNmxrje9LS0jBp0iRcvXoVtra2aNu2LdasWQOHFwZ7vK5OKt5UKmDVKmnYi0oljf2dNauAlf37rzRyOjlZlyEaDreUICIqMIUQQsgdRFGTlJQEe3t7JCYmcjxQESEEsHOn1Npz/rxU1q4dsG0bYG5ewEo/+kjqRyuOHByAffukLTCIiAiAdt/f3AuMirzTp6Vp7dlDuxwcgEmTgKFDC5H83L0LrF0rPf/rL+Ctt3QRqmGVuIWNiIgMhwkQFVk3b0qJztq1UguQhYWU9EyYIC1yWCgLFwLPngFNm3JvKiIiI8QEiIqcxEQgNFSa3p6eLpUFBgJffAFUqqSDCyQnA8uWSc+5MzkRkVFiAkSyefYM6NdP2rbiRdeuAY8eSc+bN5dmfDdooMMLL18OPH4MvPEG0L69DismIqLiggkQyWb7dmnhwtxUry4tctiunY6HumRmShuEAdIS0oVcRZyIiIonJkAkm+zkp1cvoEeP/8qtrYEmTQAzffx2bt4sDS4qWxbo00cPFyAiouKACRDJ4tEj4PffpeejRwN16hjgoi/vn2VpaYCLEhFRUcQEiArm6VPgyZMCn/7LKsA2A6hZA6hTDkCCziLL25Ej0px6Kyvun0VEZOSYAJH2jh4FWrT4b4pWAfR9/sAFAE66CEoLH30EODoa+KJERFSUcAQoaW/69EIlP7Jyc5P63IiIyKgxASLtnD8v7UlhYgJcvizNqtLyMXNqJkyRidb+2p9b6EdsLODhIfddJCIimbELjLQzd670s0sXoEoVrU8XAvhxHZAFoGcfAKY6jY6IiChf2AJE+RcbC6xfLz0v4ArKx44BV65IU907ddJhbERERFpgAkT5l71/1ttvAw0bFqiK7LV/OncGbG11GBsREZEWmABR/iQlFXr/rIwMYONG6Xnv3jqKi4iIqACYAFH+/PCDlARVqybtT1EAO3YADx9KE7FattRxfERERFpgAkSv9+yZtDU7UOD9s1JTgc8/l5736AGYcvAzERHJiLPAjE1KipTQaGPrVuDWLcDFRdq4S0vPngFduwJ//w2UKSPtQkFERCQnJkDGZOnSwm0B8dlnWu+flZUlLby8Y4e0A8XvvwOengUPgYiISBfYBWYs0tOlFZwLyssLGDRI69PGjAHWrpW6vH7+GWjUqOAhEBER6QpbgIzF2rVAfDxQvjzw77+Aubl255uaAgqFVqfMmQN8/bX0fOVKoG1b7S5JRESkL0yAjEFW1n+ZyPDhUl+Unv39t9T6A0iLR3PaOxERFSXsAjMGf/wBXLwI2NkBAwYY5JIrVkg/u3aVJo4REREVJUyAjMGcOdLPjz+WkiA9y8gANm2Snhso3yIiItIKE6CS7vhx4MABwMwMGDbMIJf84w9pwUN3d+Dddw1ySSIiIq0wASrpsndv79EDKFfOIJfM3u+LCx4SEVFRxQSoJLt6FdiyRXpewP27tPXokbTWD8CBz0REVHQxASrJ5s+XZoC1bg3Urm2QS/70kzQGqE4d6UFERFQUMQEqqRIS/puKZaDWH+C/7i+2/hARUVHGBKikWroUePIEqFfPYCORr14FDh+W9krt0cMglyQiIioQJkAlUVoasGiR9HzUKK1XcC6otWulny1bSjPAiIiIiiomQCXRmjXAvXtAxYrSSoQGIAS7v4iIqPhgAlTSvLzthbZ7fhXQ0aPAlSuAtTXQqZNBLklERFRgTIBKmt9/B6KjAXt7oH9/g1121SrpZ+fOgK2twS5LRERUIEyASprshQ8HDQJKlTLIJdevB777Tnret69BLklERFQoTIBKkmPHgIMHpW6vzz4zyCV37waCgqTnn33GrS+IiKh4YAJUkmS3/vTsaZBpWMePS11emZlAYKC07qKBJpwREREVChOgkiImBti6VXo+cqTeLxcdDbRrB6SmAv7+0hggE/42ERFRMcGvrJJi0SJpBlibNkCtWnq91LFjQEAA8OAB4Osr5V0WFnq9JBERkU4xASopdu2Sfg4cqLdLxMQA3boBb70F3LgBeHsD27cbbKw1ERGRzjABKgkSEoBLl6TnTZvqvPqHD4ERI4Dq1aXNThUKabbXgQNA2bI6vxwREZHemckdAOnAkSPSz6pVAScnnVadlgY0afJffhUQAHz1FVC3rk4vQ0REZFBMgEqCv/6SfjZpovOqv/pKSn5cXYHVq4FWrXR+CSIiIoNjF1hJkJ0ANW6s02pjYoDQUOn5ggVMfoiIqORgAlTcPXsmLcgD6DQBEgIYOhRIT5emuRtoT1UiIiKDYAJU3J05Azx9CpQuLY0B0pHwcGDHDmlR6cWLucAhERGVLLInQEuWLIGnpycsLS3h5+eH49mtGXkICwtD1apVYWVlhQoVKmDEiBFIS0tTvz9t2jQoFAqNR7Vq1fT9MeTzYveXjlYiTE0Fhg2Tno8erdO8ioiIqEiQdRD0pk2bEBISgmXLlsHPzw9hYWEICAhAdHQ0yuYyv3r9+vUYN24cVqxYgcaNG+Pff/9F3759oVAoMG/ePPVxNWvWxJ9//ql+bWZWgsd662H8z+efA7duAR4ewMSJOquWiIioyJA1M5g3bx4GDBiA4OBgAMCyZcuwfft2rFixAuPGjctx/F9//YUmTZqgR48eAABPT08EBgbi2LFjGseZmZnB1dVV/x+gKChEAiQEsHChtJ7Pi2W//y49X7gQsLbWQYxERERFjGwJUEZGBk6ePInx48ery0xMTODv748j2evavKRx48ZYu3Ytjh8/joYNG+Lq1av4448/0Lt3b43jLl++DHd3d1haWqJRo0YIDQ1FxYoV84wlPT0d6enp6tdJSUmF/HQGcvMmcPs2YGoKNGyo9ekTJ/43y+tl778P/O9/hYyPiIioiJItAXrw4AFUKhVcXFw0yl1cXHApe9W9l/To0QMPHjxA06ZNIYRAZmYmBg0ahAkTJqiP8fPzw6pVq1C1alXcvXsX06dPR7NmzXD+/HmUymPPhtDQUEyfPl13H85Qslt/6tXTuqlmwYL/kp+xYwFPz//es7CQdnknIiIqqYrV4Jh9+/bhyy+/xDfffAM/Pz9cuXIFw4YNw8yZMzF58mQAQJs2bdTH16lTB35+fvDw8MBPP/2Efv365Vrv+PHjERISon6dlJSEChUq6PfD6EIBu7/WrweGD5eef/EF8EL+SEREZBRkS4CcnJxgamqK+Ph4jfL4+Pg8x+9MnjwZvXv3Rv/+/QEAtWvXRmpqKgYOHIiJEyfCJJdZUA4ODnjjjTdw5cqVPGNRKpVQKpWF+DQyOXxY+qlFArR7NxAUJD0fOhR4oQeSiIjIaMg2Dd7CwgL169dHZGSkuiwrKwuRkZFo1KhRruc8efIkR5JjamoKABBC5HpOSkoKYmJi4ObmpqPIi4iUFCAqSnqezy0wTp2SurYyM4Hu3YGwMK7vQ0RExknWLrCQkBAEBQXB19cXDRs2RFhYGFJTU9Wzwvr06YNy5coh9Plglfbt22PevHmoV6+eugts8uTJaN++vToRGjVqFNq3bw8PDw/cuXMHU6dOhampKQIDA2X7nHpx4gSgUgEVKgDly7/28MxMaQf31FTgvfekfb10tGwQERFRsSNrAtStWzfcv38fU6ZMQVxcHHx8fLBz5071wOibN29qtPhMmjQJCoUCkyZNQmxsLJydndG+fXt88cUX6mNu376NwMBAJCQkwNnZGU2bNsXRo0fh7Oxs8M+nV1qO/1m0CDh3DnB0BDZskAY6ExERGSuFyKvvyIglJSXB3t4eiYmJsLOzkzuc3LVtK+1VsWAB8Nlnrzw0NhaoVk3qNfvhByCPseBERETFmjbf3+wEKY6ysoDstZLyMf5n5Egp+WnUCHjeu0hERGTUtE6APD09MWPGDNy8eVMf8VB+XLoEPH4srf1Tp84rD42MBDZtksb7fPMNx/0QEREBBUiAhg8fjq1bt6Jy5cp47733sHHjRo1VlMkAssf/NGwobdeeh/R0YPBg6fngwYCPj/5DIyIiKg4KlACdOXMGx48fR/Xq1TF06FC4ublhyJAhOHXqlD5ipJdlr//zmu6vefOA6GjAxQWYOdMAcRERERUTBe4QefPNN7Fw4UL1VPMffvgBDRo0gI+PD1asWJHnujykA/mYAXby5H9Jz9y5gL29AeIiIiIqJgo8Df7Zs2fYtm0bVq5ciYiICLz11lvo168fbt++jQkTJuDPP//E+vXrdRkrAcCDB8C//0rP33or10MuXwbatAGePgUCAoCePQ0YHxERUTGgdQJ06tQprFy5Ehs2bICJiQn69OmD+fPno1q1aupjOnXqhAYNGug0UHouu/WnenWgTJkcb9+9C7RqBdy/D7z5JrB5M1d7JiIiepnWCVCDBg3w3nvvYenSpejYsSPMcxmEW6lSJXTv3l0nAdJLshOgXMb/PH4MtG4NXL8OVKkiLRNUqpRBoyMiIioWtE6Arl69Cg8Pj1ceY2Njg5UrVxY4KHqFPMb/pKUBHToAZ89Kg5537QLKlpUhPiIiomJA60HQ9+7dw7Fjx3KUHzt2DH///bdOgqI8ZGRIe4ABGgnQn39Kw4EOHADs7ICdO4HKlWWKkYiIqBjQOgEaPHgwbt26laM8NjYWg7MXnSH9OH1aaupxdATeeAPnzkmDnd97T9oY3t4e+OUXrvdDRET0OlonQBcuXMCbb76Zo7xevXq4cOGCToKiPDzv/hKNGmPwEAV8fKTWHnNzYNgw4MoVoEULWSMkIiIqFrROgJRKJeLj43OU3717F2Zmsm4uX/I9T4AulWmMb76RtgTr2hW4eBEICwOcnOQNj4iIqLjQOgFq1aoVxo8fj8TERHXZ48ePMWHCBLz33ns6DY5eIIQ6AYpIlcb/DBwI/PQT4OUlZ2BERETFj9ZNNnPnzsXbb78NDw8P1KtXDwBw5swZuLi4YM2aNToPkJ67cQO4cwcwM8Oai74ApLE/REREpD2tE6By5crh7NmzWLduHaKiomBlZYXg4GAEBgbmuiYQ6cjz1p9ntd/E36etAQDvvCNnQERERMVXgQbt2NjYYODAgbqOhV7leQJ01VXq/vLxkSaDERERkfYKPGr5woULuHnzJjIyMjTK//e//xU6KMrF8x3g96ZLCVDLlnIGQ0REVLwVaCXoTp064dy5c1AoFOpd3xXPN5xSqVS6jZCA5GRpiWcAq69IW2C8+66cARERERVvWs8CGzZsGCpVqoR79+7B2toa//zzDw4cOABfX1/s27dPDyESjh8HsrKQWc4DR2+6w8wMaNZM7qCIiIiKL61bgI4cOYI9e/bAyckJJiYmMDExQdOmTREaGorPPvsMp0+f1kecxu35+J8b5RsDsUDDhtzklIiIqDC0bgFSqVQo9fzb18nJCXfu3AEAeHh4IDo6WrfRkeTAAQDAwUxp/A+7v4iIiApH6xagWrVqISoqCpUqVYKfnx9mz54NCwsLfPfdd6jMHTh17/JlIDISAPD9jVYAOACaiIiosLROgCZNmoTU1FQAwIwZM/D++++jWbNmcHR0xKZNm3QeoNGbNw8QAsnN38df+9+ApaW08zsREREVnNYJUEBAgPp5lSpVcOnSJTx8+BClS5dWzwQjHbl3D1i1CgAQ4TMa2A80bQpYWsobFhERUXGn1RigZ8+ewczMDOfPn9coL1OmDJMfffjmGyAtDWjQAGuuS9O+OP6HiIio8LRKgMzNzVGxYkWu9WMIT54AixcDAFQjR2PffinB5PgfIiKiwtN6FtjEiRMxYcIEPHz4UB/xULbVq4GEBKBSJZzx7ITHjwE7O+DNN+UOjIiIqPjTegzQ4sWLceXKFbi7u8PDwwM2NjYa7586dUpnwRktlQr4+mvpeUgIIvdLf0zNmwNmBd68hIiIiLJp/XXasWNHPYRBGsLDgZgYoEwZIDgYe7pIxez+IiIi0g2tE6CpU6fqIw7KJgQwZ470/NNPIaxtcOyY9JLbXxAREemG1mOASM8OHwaOHQOUSmDIEFy9Cjx+LL2sVUvu4IiIiEoGrVuATExMXjnlnTPECmnuXOlnnz6Aiwv+3ie9rFMHsLCQLSoiIqISResEaNu2bRqvnz17htOnT2P16tWYPn26zgIzStHRwK+/Ss9HjgQAnDwpvfT1lSkmIiKiEkjrBKhDhw45yj744APUrFkTmzZtQr9+/XQSmFF6vu0F/vc/oGpVAMDff0tvMQEiIiLSHZ2NAXrrrbcQ+XzTTiqA+Hhp7R8AGDUKAJCV9V8LUP36MsVFRERUAukkAXr69CkWLlyIcuXK6aI647RkCZCeDvj5SRt+QZoJn5Qk7f1Vo4bM8REREZUgWneBvbzpqRACycnJsLa2xtq1a3UanNFITZUSIEBq/Xl+f7O7v3x8AHNzeUIjIiIqibROgObPn6+RAJmYmMDZ2Rl+fn4oXbq0ToMzGqtWAQ8fApUrA506qYuzEyB2fxEREemW1glQ37599RCGEVOppMHPABASApiaqt/iAGgiIiL90HoM0MqVK7F58+Yc5Zs3b8bq7EG8lH/btgFXrwKOjkBwsLo4KwvI3laNCRAREZFuaZ0AhYaGwsnJKUd52bJl8eWXX+okKKMyf77089NPAWtrdfG//wIpKYCVFVCtmkyxERERlVBaJ0A3b95EpUqVcpR7eHjg5s2bOgnKaDx+DBw5Ij3/+GONt7K7v+rV4w7wREREuqZ1AlS2bFmcPXs2R3lUVBQcHR11EpTROHpUWvjQywt4aQkBrgBNRESkP1onQIGBgfjss8+wd+9eqFQqqFQq7NmzB8OGDUP37t31EWPJ9ddf0s8mTXK8xRlgRERE+qN158rMmTNx/fp1tGzZEmbP+2aysrLQp08fjgHSVnYC1LixRrFKxQHQRERE+qR1C5CFhQU2bdqE6OhorFu3Dlu3bkVMTAxWrFgBiwJsV75kyRJ4enrC0tISfn5+OH78+CuPDwsLQ9WqVWFlZYUKFSpgxIgRSEtLK1SdssjMBI4dk56/lABFRwNPngA2NuotwYiIiEiHCjy81tvbG97e3oW6+KZNmxASEoJly5bBz88PYWFhCAgIQHR0NMqWLZvj+PXr12PcuHFYsWIFGjdujH///Rd9+/aFQqHAvOdr6Whbp2zOnZOmednZ5djn4sUB0C8sC0REREQ6onULUJcuXfDVV1/lKJ89eza6du2qVV3z5s3DgAEDEBwcjBo1amDZsmWwtrbGihUrcj3+r7/+QpMmTdCjRw94enqiVatWCAwM1Gjh0bZO2WR3fzVqlCPL4QKIRERE+qV1AnTgwAG0bds2R3mbNm1w4MCBfNeTkZGBkydPwt/f/79gTEzg7++PI9lTw1/SuHFjnDx5Up3wXL16FX/88Yc6noLUCQDp6elISkrSeOhdHuN/AM4AIyIi0jetu8BSUlJyHetjbm6uVeLw4MEDqFQquLi4aJS7uLjg0qVLuZ7To0cPPHjwAE2bNoUQApmZmRg0aBAmTJhQ4DoBaXHH6dOn5zt2ncgjAcrMBE6flp5zBhgREZF+aN0CVLt2bWzatClH+caNG1HjpbEsurZv3z58+eWX+Oabb3Dq1Cls3boV27dvx8yZMwtV7/jx45GYmKh+3Lp1S0cR5+HOHeD6dcDEBPDz03jr4kXg6VPA1hZ44w39hkFERGSstG4Bmjx5Mjp37oyYmBi8++67AIDIyEisX78eP//8c77rcXJygqmpKeLj4zXK4+Pj4erqmue1e/fujf79+wOQkrHU1FQMHDgQEydOLFCdAKBUKqFUKvMde6Flt/7UqQOUKqXxVvb09zfflPIjIiIi0j2tv2Lbt2+P8PBwXLlyBZ9++ilGjhyJ2NhY7NmzB1WqVMl3PRYWFqhfvz4iIyPVZVlZWYiMjESjRo1yPefJkycweSkrMH0+gFgIUaA6ZfGK8T9RUdJPHx/DhUNERGRsCjQNvl27dmjXrh0AICkpCRs2bMCoUaNw8uRJqFSqfNcTEhKCoKAg+Pr6omHDhggLC0NqaiqCn++K3qdPH5QrVw6hoaEApORr3rx5qFevHvz8/HDlyhVMnjwZ7du3VydCr6uzSMhHAlS3rgHjISIiMjIFXgfowIEDWL58ObZs2QJ3d3d07twZS5Ys0aqObt264f79+5gyZQri4uLg4+ODnTt3qgcx37x5U6PFZ9KkSVAoFJg0aRJiY2Ph7OyM9u3b44svvsh3nbJ7+vS/fq6XEiAhmAAREREZgkIIIfJ7cFxcHFatWoXly5cjKSkJH374IZYtW4aoqCi9D4A2pKSkJNjb2yMxMRF2dna6rfzgQeDttwE3NyA2FlAo1G/duSPtiWpiIq2RaGWl20sTERGVZNp8f+d7DFD79u1RtWpVnD17FmFhYbhz5w4WLVpU6GCNzovdXy8kPwBw9qz0s2pVJj9ERET6lO8usB07duCzzz7DJ598UugtMIxaPsb/1KljwHiIiIiMUL5bgA4dOoTk5GTUr18ffn5+WLx4MR48eKDP2EoeIf5LgJo0yfF2dgsQx/8QERHpV74ToLfeegvff/897t69i48//hgbN26Eu7s7srKyEBERgeTkZH3GWTJcvgw8eAAoldJOpy9hCxAREZFhaL0OkI2NDT766CMcOnQI586dw8iRIzFr1iyULVsW//vf//QRY8mR3frToAHw0nYi6elA9m4dbAEiIiLSr0KtNVy1alXMnj0bt2/fxoYNG3QVU8n177/Sz1zG/1y4AKhUQOnS0kwwIiIi0h+tpsEbC71Og79/X8p0XtqaY/VqoG9foEULYO9e3V6SiIjIGGjz/V3ghRCpgJydcy3m+B8iIiLD4XabRQRXgCYiIjIcJkBFALfAICIiMiwmQEXA3btAQoK0BUYJ2lGEiIioyGICVARwCwwiIiLDYgJUBHAANBERkWExASoCuAUGERGRYTEBKgLYAkRERGRYTIBkxi0wiIiIDI8JkMy4BQYREZHhMQGS2YvjfxQKeWMhIiIyFkyAZMbxP0RERIbHBEhmnAFGRERkeEyAZHbhgvSzdm154yAiIjImTIBklpQk/XR0lDcOIiIiY8IESEZCAE+eSM+treWNhYiIyJgwAZJRRoaUBAHcA4yIiMiQmADJKLv1B2ALEBERkSExAZJRdgJkZgaYm8sbCxERkTFhAiSjp0+ln+z+IiIiMiwmQDLiAGgiIiJ5MAGSERMgIiIieTABklF2FxgTICIiIsNiAiSj7BYgjgEiIiIyLCZAMmIXGBERkTyYAMmIXWBERETyYAIkI3aBERERyYMJkIzYBUZERCQPJkAyYhcYERGRPJgAyYhdYERERPJgAiQjdoERERHJgwmQjJgAERERyYMJkIy4GSoREZE8mADJiC1ARERE8mACJCMmQERERPJgAiQjdoERERHJgwmQjNgCREREJA8mQDJiAkRERCQPJkAy4krQRERE8igSCdCSJUvg6ekJS0tL+Pn54fjx43ke26JFCygUihyPdu3aqY/p27dvjvdbt25tiI+iFa4ETUREJA8zuQPYtGkTQkJCsGzZMvj5+SEsLAwBAQGIjo5G2bJlcxy/detWZGRkqF8nJCSgbt266Nq1q8ZxrVu3xsqVK9WvlUql/j5EAbELjIiISB6ytwDNmzcPAwYMQHBwMGrUqIFly5bB2toaK1asyPX4MmXKwNXVVf2IiIiAtbV1jgRIqVRqHFe6dGlDfBytsAuMiIhIHrImQBkZGTh58iT8/f3VZSYmJvD398eRI0fyVcfy5cvRvXt32NjYaJTv27cPZcuWRdWqVfHJJ58gISEhzzrS09ORlJSk8dC3zEwguyGLXWBERESGJWsC9ODBA6hUKri4uGiUu7i4IC4u7rXnHz9+HOfPn0f//v01ylu3bo0ff/wRkZGR+Oqrr7B//360adMGKpUq13pCQ0Nhb2+vflSoUKHgHyqfslt/ALYAERERGZrsY4AKY/ny5ahduzYaNmyoUd69e3f189q1a6NOnTrw8vLCvn370LJlyxz1jB8/HiEhIerXSUlJek+Cssf/AIClpV4vRURERC+RtQXIyckJpqamiI+P1yiPj4+Hq6vrK89NTU3Fxo0b0a9fv9dep3LlynBycsKVK1dyfV+pVMLOzk7joW8vrgKtUOj9ckRERPQCWRMgCwsL1K9fH5GRkeqyrKwsREZGolGjRq88d/PmzUhPT0evXr1ee53bt28jISEBbm5uhY5ZVzgDjIiISD6yzwILCQnB999/j9WrV+PixYv45JNPkJqaiuDgYABAnz59MH78+BznLV++HB07doSjo6NGeUpKCkaPHo2jR4/i+vXriIyMRIcOHVClShUEBAQY5DPlBxMgIiIi+cg+Bqhbt264f/8+pkyZgri4OPj4+GDnzp3qgdE3b96EiYlmnhYdHY1Dhw5h9+7dOeozNTXF2bNnsXr1ajx+/Bju7u5o1aoVZs6cWaTWAuJGqERERPJRCCGE3EEUNUlJSbC3t0diYqLexgPt2gW0bg34+ACnT+vlEkREREZFm+9v2bvAjBW7wIiIiOTDBEgm7AIjIiKSDxMgmbAFiIiISD5MgGTCBIiIiEg+TIBkwo1QiYiI5MMESCbZLUAcA0RERGR4TIBkwi4wIiIi+TABkgm7wIiIiOTDBEgm7AIjIiKSDxMgmbALjIiISD5MgGTCBIiIiEg+TIBkwpWgiYiI5MMESCZsASIiIpIPEyCZMAEiIiKSDxMgmbALjIiISD5MgGTCFiAiIiL5MAGSCRMgIiIi+TABkgm7wIiIiOTDBEgGQrAFiIiISE5MgGSQlvbfcyZAREREhscESAbZ3V8Au8CIiIjkwARIBtndX+bmgJmZvLEQEREZIyZAMuD4HyIiInkxAZIBEyAiIiJ5MQGSAafAExERyYsJkAzYAkRERCQvJkAyYAJEREQkLyZAMmAXGBERkbyYAMmALUBERETyYgIkAyZARERE8mICJAN2gREREcmLCZAM2AJEREQkLyZAMmACREREJC8mQDJgFxgREZG8mADJgC1ARERE8mICJAMmQERERPJiAiQDdoERERHJiwmQDNgCREREJC8mQDJgAkRERCQvJkAyYAJEREQkLyZAMuAYICIiInkxAZIBW4CIiIjkxQRIBkyAiIiI5MUESAbsAiMiIpIXEyAZsAWIiIhIXkyADOzZMyAzU3rOBIiIiEgeRSIBWrJkCTw9PWFpaQk/Pz8cP348z2NbtGgBhUKR49GuXTv1MUIITJkyBW5ubrCysoK/vz8uX75siI/yWtndXwC7wIiIiOQiewK0adMmhISEYOrUqTh16hTq1q2LgIAA3Lt3L9fjt27dirt376of58+fh6mpKbp27ao+Zvbs2Vi4cCGWLVuGY8eOwcbGBgEBAUhLSzPUx8pTdveXQgEolfLGQkREZKxkT4DmzZuHAQMGIDg4GDVq1MCyZctgbW2NFStW5Hp8mTJl4Orqqn5ERETA2tpanQAJIRAWFoZJkyahQ4cOqFOnDn788UfcuXMH4eHhBvxkuXtx/I9CIW8sRERExkrWBCgjIwMnT56Ev7+/uszExAT+/v44cuRIvupYvnw5unfvDhsbGwDAtWvXEBcXp1Gnvb09/Pz88qwzPT0dSUlJGg994QwwIiIi+cmaAD148AAqlQouLi4a5S4uLoiLi3vt+cePH8f58+fRv39/dVn2edrUGRoaCnt7e/WjQoUK2n6UfOMMMCIiIvnJ3gVWGMuXL0ft2rXRsGHDQtUzfvx4JCYmqh+3bt3SUYQ5MQEiIiKSn6wJkJOTE0xNTREfH69RHh8fD1dX11eem5qaio0bN6Jfv34a5dnnaVOnUqmEnZ2dxkNfshMgdoERERHJR9YEyMLCAvXr10dkZKS6LCsrC5GRkWjUqNErz928eTPS09PRq1cvjfJKlSrB1dVVo86kpCQcO3bstXUaQvYYILYAERERycdM7gBCQkIQFBQEX19fNGzYEGFhYUhNTUVwcDAAoE+fPihXrhxCQ0M1zlu+fDk6duwIR0dHjXKFQoHhw4fj888/h7e3NypVqoTJkyfD3d0dHTt2NNTHyhO7wIiIiOQnewLUrVs33L9/H1OmTEFcXBx8fHywc+dO9SDmmzdvwsREs6EqOjoahw4dwu7du3Otc8yYMUhNTcXAgQPx+PFjNG3aFDt37oSlpaXeP8/rMAEiIiKSn0IIIeQOoqhJSkqCvb09EhMTdT4eaMECYPhwoHt3YMMGnVZNRERk1LT5/i7Ws8CKI7YAERERyY8JkIExASIiIpIfEyAD40rQRERE8mMCZGBsASIiIpIfEyADYwJEREQkPyZABsYuMCIiIvkxATIwtgARERHJjwmQgTEBIiIikh8TIANjFxgREZH8mAAZGFuAiIiI5McEyMCYABEREcmPCZCBZSdA7AIjIiKSDxMgA8seA8QWICIiIvkwATIwdoERERHJjwmQAWVlAWlp0nMmQERERPJhAmRA2ckPwDFAREREcmICZEDZ3V8AEyAiIiI5MQEyoOwESKkETE3ljYWIiMiYMQEyIK4CTUREVDQwATIgzgAjIiIqGpgAGRATICIioqKBCZABsQuMiIioaGACZEBsASIiIioamAAZEBMgIiKiooEJkAGxC4yIiKhoYAJkQGwBIiIiKhqYABkQEyAiIqKigQmQAQkhdX8xASIiIpKXQggh5A6iqElKSoK9vT0SExNhZ2en8/qFABQKnVdLRERk1LT5/mYLkAyY/BAREcmLCRAREREZHSZAREREZHSYABEREZHRYQJERERERocJEBERERkdJkBERERkdJgAERERkdFhAkRERERGhwkQERERGR0mQERERGR0mAARERGR0WECREREREaHCRAREREZHTO5AyiKhBAAgKSkJJkjISIiovzK/t7O/h5/FSZAuUhOTgYAVKhQQeZIiIiISFvJycmwt7d/5TEKkZ80ychkZWXhzp07KFWqFBQKRYHrSUpKQoUKFXDr1i3Y2dnpMEJ6Ge+14fBeGw7vteHwXhuOPu+1EALJyclwd3eHicmrR/mwBSgXJiYmKF++vM7qs7Oz418oA+G9Nhzea8PhvTYc3mvD0de9fl3LTzYOgiYiIiKjwwSIiIiIjA4TID1SKpWYOnUqlEql3KGUeLzXhsN7bTi814bDe204ReVecxA0ERERGR22ABEREZHRYQJERERERocJEBERERkdJkBERERkdJgA6dGSJUvg6ekJS0tL+Pn54fjx43KHVKyFhoaiQYMGKFWqFMqWLYuOHTsiOjpa45i0tDQMHjwYjo6OsLW1RZcuXRAfHy9TxCXHrFmzoFAoMHz4cHUZ77XuxMbGolevXnB0dISVlRVq166Nv//+W/2+EAJTpkyBm5sbrKys4O/vj8uXL8sYcfGlUqkwefJkVKpUCVZWVvDy8sLMmTM19o7i/S6YAwcOoH379nB3d4dCoUB4eLjG+/m5rw8fPkTPnj1hZ2cHBwcH9OvXDykpKXqJlwmQnmzatAkhISGYOnUqTp06hbp16yIgIAD37t2TO7Ria//+/Rg8eDCOHj2KiIgIPHv2DK1atUJqaqr6mBEjRuC3337D5s2bsX//fty5cwedO3eWMeri78SJE/j2229Rp04djXLea9149OgRmjRpAnNzc+zYsQMXLlzA119/jdKlS6uPmT17NhYuXIhly5bh2LFjsLGxQUBAANLS0mSMvHj66quvsHTpUixevBgXL17EV199hdmzZ2PRokXqY3i/CyY1NRV169bFkiVLcn0/P/e1Z8+e+OeffxAREYHff/8dBw4cwMCBA/UTsCC9aNiwoRg8eLD6tUqlEu7u7iI0NFTGqEqWe/fuCQBi//79QgghHj9+LMzNzcXmzZvVx1y8eFEAEEeOHJErzGItOTlZeHt7i4iICNG8eXMxbNgwIQTvtS6NHTtWNG3aNM/3s7KyhKurq5gzZ4667PHjx0KpVIoNGzYYIsQSpV27duKjjz7SKOvcubPo2bOnEIL3W1cAiG3btqlf5+e+XrhwQQAQJ06cUB+zY8cOoVAoRGxsrM5jZAuQHmRkZODkyZPw9/dXl5mYmMDf3x9HjhyRMbKSJTExEQBQpkwZAMDJkyfx7NkzjfterVo1VKxYkfe9gAYPHox27dpp3FOA91qXfv31V/j6+qJr164oW7Ys6tWrh++//179/rVr1xAXF6dxr+3t7eHn58d7XQCNGzdGZGQk/v33XwBAVFQUDh06hDZt2gDg/daX/NzXI0eOwMHBAb6+vupj/P39YWJigmPHjuk8Jm6GqgcPHjyASqWCi4uLRrmLiwsuXbokU1QlS1ZWFoYPH44mTZqgVq1aAIC4uDhYWFjAwcFB41gXFxfExcXJEGXxtnHjRpw6dQonTpzI8R7vte5cvXoVS5cuRUhICCZMmIATJ07gs88+g4WFBYKCgtT3M7d/T3ivtTdu3DgkJSWhWrVqMDU1hUqlwhdffIGePXsCAO+3nuTnvsbFxaFs2bIa75uZmaFMmTJ6ufdMgKhYGjx4MM6fP49Dhw7JHUqJdOvWLQwbNgwRERGwtLSUO5wSLSsrC76+vvjyyy8BAPXq1cP58+exbNkyBAUFyRxdyfPTTz9h3bp1WL9+PWrWrIkzZ85g+PDhcHd35/02MuwC0wMnJyeYmprmmBETHx8PV1dXmaIqOYYMGYLff/8de/fuRfny5dXlrq6uyMjIwOPHjzWO533X3smTJ3Hv3j28+eabMDMzg5mZGfbv34+FCxfCzMwMLi4uvNc64ubmhho1amiUVa9eHTdv3gQA9f3kvye6MXr0aIwbNw7du3dH7dq10bt3b4wYMQKhoaEAeL/1JT/31dXVNcdEoczMTDx8+FAv954JkB5YWFigfv36iIyMVJdlZWUhMjISjRo1kjGy4k0IgSFDhmDbtm3Ys2cPKlWqpPF+/fr1YW5urnHfo6OjcfPmTd53LbVs2RLnzp3DmTNn1A9fX1/07NlT/Zz3WjeaNGmSYzmHf//9Fx4eHgCASpUqwdXVVeNeJyUl4dixY7zXBfDkyROYmGh+9ZmamiIrKwsA77e+5Oe+NmrUCI8fP8bJkyfVx+zZswdZWVnw8/PTfVA6H1ZNQgghNm7cKJRKpVi1apW4cOGCGDhwoHBwcBBxcXFyh1ZsffLJJ8Le3l7s27dP3L17V/148uSJ+phBgwaJihUrij179oi///5bNGrUSDRq1EjGqEuOF2eBCcF7rSvHjx8XZmZm4osvvhCXL18W69atE9bW1mLt2rXqY2bNmiUcHBzEL7/8Is6ePSs6dOggKlWqJJ4+fSpj5MVTUFCQKFeunPj999/FtWvXxNatW4WTk5MYM2aM+hje74JJTk4Wp0+fFqdPnxYAxLx588Tp06fFjRs3hBD5u6+tW7cW9erVE8eOHROHDh0S3t7eIjAwUC/xMgHSo0WLFomKFSsKCwsL0bBhQ3H06FG5QyrWAOT6WLlypfqYp0+fik8//VSULl1aWFtbi06dOom7d+/KF3QJ8nICxHutO7/99puoVauWUCqVolq1auK7777TeD8rK0tMnjxZuLi4CKVSKVq2bCmio6NlirZ4S0pKEsOGDRMVK1YUlpaWonLlymLixIkiPT1dfQzvd8Hs3bs313+jg4KChBD5u68JCQkiMDBQ2NraCjs7OxEcHCySk5P1Eq9CiBeWvyQiIiIyAhwDREREREaHCRAREREZHSZAREREZHSYABEREZHRYQJERERERocJEBERERkdJkBERERkdJgAERHlQaFQIDw8XO4wiEgPmAARUZHUt29fKBSKHI/WrVvLHRoRlQBmcgdARJSX1q1bY+XKlRplSqVSpmiIqCRhCxARFVlKpRKurq4aj9KlSwOQuqeWLl2KNm3awMrKCpUrV8bPP/+scf65c+fw7rvvwsrKCo6Ojhg4cCBSUlI0jlmxYgVq1qwJpVIJNzc3DBkyROP9Bw8eoFOnTrC2toa3tzd+/fVX9XuPHj1Cz5494ezsDCsrK3h7e+dI2IioaGICRETF1uTJk9GlSxdERUWhZ8+e6N69Oy5evAgASE1NRUBAAEqXLo0TJ05g8+bN+PPPPzUSnKVLl2Lw4MEYOHAgzp07h19//RVVqlTRuMb06dPx4Ycf4uzZs2jbti169uyJhw8fqq9/4cIF7NixAxcvXsTSpUvh5ORkuBtARAWnly1WiYgKKSgoSJiamgobGxuNxxdffCGEEAKAGDRokMY5fn5+4pNPPhFCCPHdd9+J0qVLi5SUFPX727dvFyYmJiIuLk4IIYS7u7uYOHFinjEAEJMmTVK/TklJEQDEjh07hBBCtG/fXgQHB+vmAxORQXEMEBEVWe+88w6WLl2qUVamTBn180aNGmm816hRI5w5cwYAcPHiRdStWxc2Njbq95s0aYKsrCxER0dDoVDgzp07aNmy5StjqFOnjvq5jY0N7OzscO/ePQDAJ598gi5duuDUqVNo1aoVOnbsiMaNGxfosxKRYTEBIqIiy8bGJkeXlK5YWVnl6zhzc3ON1wqFAllZWQCANm3a4MaNG/jjjz8QERGBli1bYvDgwZg7d67O4yUi3eIYICIqto4ePZrjdfXq1QEA1atXR1RUFFJTU9XvHz58GCYmJqhatSpKlSoFT09PREZGFioGZ2dnBAUFYe3atQgLC8N3331XqPqIyDDYAkRERVZ6ejri4uI0yszMzNQDjTdv3gxfX180bdoU69atw/Hjx7F8+XIAQM+ePTF16lQEBQVh2rRpuH//PoYOHYrevXvDxcUFADBt2jQMGjQIZcuWRZs2bZCcnIzDhw9j6NCh+YpvypQpqF+/PmrWrIn09HT8/vvv6gSMiIo2JkBEVGTt3LkTbm5uGmVVq1bFpUuXAEgztDZu3IhPP/0Ubm5u2LBhA2rUqAEAsLa2xq5duzBs2DA0aNAA1tbW6NKlC+bNm6euKygoCGlpaZg/fz5GjRoFJycnfPDBB/mOz8LCAuPHj8f169dhZWWFZs2aYePGjTr45ESkbwohhJA7CCIibSkUCmzbtg0dO3aUOxQiKoY4BoiIiIiMDhMgIiIiMjocA0RExRJ774moMNgCREREREaHCRAREREZHSZAREREZHSYABEREZHRYQJERERERocJEBERERkdJkBERERkdJgAERERkdFhAkRERERG5/9jrMoF6B2mQAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a acurácia de treinamento mede o desempenho do modelo nos dados de treinamento, enquanto a acurácia de validação mede o desempenho em dados não vistos. Ambas são métricas importantes para avaliar a qualidade do modelo durante o treinamento."
      ],
      "metadata": {
        "id": "EBs_dZiREcME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Claro! Vou explicar cada um desses modelos de avaliação de desempenho de modelos de classificação:\n",
        "\n",
        "1. **Precisão (Precision):** A precisão mede a proporção de exemplos classificados corretamente como positivos em relação ao total de exemplos classificados como positivos. Em outras palavras, é a capacidade do modelo de evitar falsos positivos. Uma alta precisão indica que o modelo tem uma baixa taxa de falsos positivos.\n",
        "\n",
        "2. **Recall (Sensibilidade ou Revocação):** O recall mede a proporção de exemplos positivos que foram corretamente classificados como positivos em relação ao total de exemplos positivos reais. É a capacidade do modelo de evitar falsos negativos. Um alto recall indica que o modelo tem uma baixa taxa de falsos negativos.\n",
        "\n",
        "3. **F1-score:** O F1-score é uma métrica que combina a precisão e o recall em um único valor, calculado a partir da média harmônica entre essas duas métricas. É útil quando se deseja considerar tanto a precisão quanto o recall ao avaliar o desempenho do modelo. O F1-score tende a ser mais adequado quando há um desequilíbrio entre as classes ou quando os custos de falsos positivos e falsos negativos são altos e não podem ser tratados de forma equivalente.\n",
        "\n",
        "4. **Matriz de Confusão:** A matriz de confusão é uma tabela que mostra a contagem de previsões corretas e incorretas feitas por um modelo de classificação. Ela apresenta quatro valores: verdadeiros positivos (TP), falsos positivos (FP), verdadeiros negativos (TN) e falsos negativos (FN). A matriz de confusão é útil para ter uma visão geral do desempenho do modelo em cada classe e para calcular métricas como precisão, recall e acurácia.\n",
        "\n",
        "5. **Curvas ROC (Receiver Operating Characteristic):** As curvas ROC são usadas para avaliar o desempenho de modelos de classificação binária em diferentes níveis de threshold (limiar de classificação). Elas plotam a taxa de verdadeiros positivos (TPR) em relação à taxa de falsos positivos (FPR) para diferentes valores de threshold. A área sob a curva ROC (AUC-ROC) é uma métrica comum usada para comparar diferentes modelos e representa a capacidade geral do modelo de distinguir entre classes positivas e negativas. Quanto maior a AUC-ROC, melhor o desempenho do modelo.\n",
        "\n",
        "Essas métricas e conceitos são amplamente utilizados na avaliação de modelos de classificação e ajudam a entender diferentes aspectos do desempenho do modelo. É importante considerar essas métricas em conjunto para obter uma visão completa do desempenho e tomar decisões informadas sobre o modelo."
      ],
      "metadata": {
        "id": "yFn7NbBaIQds"
      }
    }
  ]
}